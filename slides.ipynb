{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94275820",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "import transformers\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import banking  # noqa: E402\n",
    "from private_prompting import Prompter\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "open_ai_key = os.environ.get(\"openai-key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b54edc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Download data and initialize a DuckDB instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a3cb54",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "_ = banking.BankingData(\"https://tinyurl.com/jb-bank\", \"bank\")\n",
    "_.extract_to_csv()\n",
    "\n",
    "# Loading in SQL extension\n",
    "%reload_ext sql\n",
    "# Initiating a DuckDB database named 'bank.duck.db' to run our SQL queries on\n",
    "%sql duckdb:///bank.duck.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b58650",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Create table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cec2da1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql CREATE OR REPLACE TABLE bank AS FROM read_csv_auto('bank_cleaned.csv', header=True, sep=',')\n",
    "# Extract column names\n",
    "columns = %sql PRAGMA table_info('bank');\n",
    "column_names = [row[1] for row in columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c18c8a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompts & Agents</h1>\n",
    "\n",
    "<h2 align='center'>How to incorporate prompting into your Python scripts <br>and expand their functionality through agents</h2>\n",
    "\n",
    "<h2 align='center'>Laura Funderburk</h2>\n",
    "\n",
    "<h2 align='center'>PyData Vancouver</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b666908",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>About me</h1>\n",
    "\n",
    "* Developer Advocate @ Ploomber (talking and sharing knowledge about tools to improve the data science workflow)\n",
    "\n",
    "* Previously a data scientist (for-profit, not-for-profit sectors)\n",
    "\n",
    "* Deeply curious about generative AI, Large Language Models, with a focus on engineering and automation\n",
    "\n",
    "* Currently use LLMs, prompting and agents to automate work tasks \n",
    "\n",
    "* BJJ enthusiast. Working towards a blue belt end of year. Competing at CBJJF Internationals September"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80b748",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Talk at a glance</h1>\n",
    "\n",
    "<h2 align='center'>Part I: Prompting (25 minutes)</h2>\n",
    "\n",
    "\n",
    "1. LLMs use cases and tasks\n",
    "2. The Generative AI project lifecycle \n",
    "3. Choosing the right LLM for the desired task\n",
    "4. Key elements of prompting & prompting techniques\n",
    "5. Prompting private LLMs (OpenAI API): `ChatCompletion`\n",
    "6. Prompting open source LLMs through HuggingFace\n",
    "\n",
    "\n",
    "Q&A about prompting (5 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6bc99d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Talk at a glance</h1>\n",
    "\n",
    "<h2 align='center'>Part II: Agents and open source frameworks (25 minutes)</h2>\n",
    "\n",
    "1. NLP pipelines and chaining\n",
    "2. Introduction to Haystack\n",
    "3. Introduction to LangChain\n",
    "4. Which one to pick\n",
    "5. Techniques to combine prompting and agents for deployment of applications\n",
    "\n",
    "Q&A about agents (5 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e4c686",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Part I: Prompting</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1efe1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>LLMs use cases and tasks</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1f923",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>LLMs use cases and tasks</h1>\n",
    "\n",
    "\n",
    "* Text summarization\n",
    "\n",
    "* Conversation \n",
    "\n",
    "* Translation\n",
    "\n",
    "* Text generation\n",
    "\n",
    "* Text, token and sentiment classification\n",
    "\n",
    "* Table Q&A and Q&A from unstructured data\n",
    "\n",
    "* Sentence similarity\n",
    "\n",
    "* Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4370d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>LLMs use cases and tasks</h1>\n",
    "\n",
    "<h3 align='center'>Your goal is to understand the business case you are solving -<br> then select the appropriate methods to solve it</h3>\n",
    "\n",
    "<h4 align='center'>Who will benefit from your product?</h4>\n",
    "\n",
    "<h4 align='center'>What are business constraints (time, data, resources)?</h4>\n",
    "\n",
    "<h4 align='center'>What is the end result?</h4>\n",
    "\n",
    "<h4 align='center'>How will it be served?</h4>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f6595",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>The generative AI project lifecycle</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f2a51",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>The generative AI project lifecycle</h1>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<center>\n",
    "  <img src=\"diagrams/genai_project_lifecycle.jpg\" width=\"1400px\"/>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ecc728",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Focus of this talk</h1>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/genai_project_lifecycle_focus.jpg\" width=\"1400px\"/>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68a8bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Choosing the right LLM (architecture) for the desired task</h1>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/opt.jpeg\" width=\"200px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "* Decoder-only transformers: Good for **generative tasks** (auto-regressive)\n",
    "* Encoder-only transformers: Good for tasks that require **understanding of the input** (auto-encoding)\n",
    "* Encoder-decoder transformers or sequence-to-sequence models: Good for **generative tasks that require an input** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0dfd13",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Choosing the right LLM (architecture) for the desired task</h1>\n",
    "\n",
    "| Tranformer type | Architecture|Model-like | Focus | Example| \n",
    "|-|-|-|-|-|\n",
    "| Auto-regressive | Decoder-only |GPT-like | Generative tasks | Chat bot | \n",
    "| Auto-encoding | Encoder-only |BERT-like | Understanding of the input | Question-answering|\n",
    "| Sequence-to-Sequence |Encoder-decoder |BART/T5-like | Generative tasks that require an input | Language translation|\n",
    "\n",
    "Read more\n",
    "\n",
    "https://github.com/christianversloot/machine-learning-articles/blob/main/differences-between-autoregressive-autoencoding-and-sequence-to-sequence-models-in-machine-learning.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939aeee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Do I need to train a new model to solve my problem?</h1>\n",
    "\n",
    "<h3 align='center'>No. Training a LLM is costly (GPU usage, time, compute, data). This is why sharing LLMs and their fine-tuned componets has become highly popularized.</h3>\n",
    "\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/hftasks.png\" width=\"1300px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "<h3 align='center'>You can start with prompting a LLM, then fine-tuning* if you aren't getting the results you want. <br>You'll need to curate a dataset for this. </h3>\n",
    "\n",
    "*(instruction-tuning or, PEFT + LoRA for example)\n",
    "\n",
    "Source: https://huggingface.co/tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ef893",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c31ef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Key elements of prompting</h1>\n",
    "\n",
    "<h3 align='center'>Basic</h3>\n",
    "\n",
    "* A LLM to interact with\n",
    "* Temperature\n",
    "* Max tokens\n",
    "* A natural language request\n",
    "\n",
    "<h3 align='center'>Advanced</h3>\n",
    "\n",
    "* Data (text files, web files)\n",
    "* A database storage system (vector DB, SQL, PostgreSQL, etc)\n",
    "* User interfaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c2b5e7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting techniques</h1>\n",
    "\n",
    "* Zero-shot inference\n",
    "\n",
    "* One-shot inference\n",
    "\n",
    "* Few-shot inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175457fa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting techniques: Zero-shot inference</h1>\n",
    "\n",
    "**Formula: instruction, no examples.**\n",
    "\n",
    "Suppose we want to translate natural language queries into SQL. \n",
    "\n",
    "We have a `natural_question`, a database table name `db_name` and a schema `schema`\n",
    "\n",
    "```python\n",
    "prompt= f\"Answer the question {natural_question} for table {db_name} with schema {schema}\"        \n",
    "```\n",
    "\n",
    "Suppose we want to classify the sentiment in a sentence `sentence`\n",
    "\n",
    "```python\n",
    "prompt = f\"How does the author feel about this based on the statement {sentence}\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5554f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting techniques: One-shot inference</h1>\n",
    "\n",
    "**Formula: instruction, one example.**\n",
    "\n",
    "```python\n",
    "prompt= f\"Answer the question {natural_question} for table {db_name} with schema {schema}\\\n",
    "                        For example, if you receive the question: 'How many records are there?'\\\n",
    "                        An appropriate answer is\\\n",
    "                        'SELECT COUNT(*) FROM bank'\"\n",
    "```\n",
    "\n",
    "```python\n",
    "prompt = f\"How does the author feel about this based on the statement {sentence}\\\n",
    "            'I find the user experience is confusing and convoluted'\\\n",
    "            Answer: Negative\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db916187",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting techniques: Few-shot inference</h1>\n",
    "\n",
    "**Formula: instruction, more than one example.**\n",
    "\n",
    "```python\n",
    "prompt= f\"Answer the question {natural_question} for table {db_name} with schema {schema}\\\n",
    "                        Example:\\\n",
    "                        'How many records are there?'\\\n",
    "                        'SELECT COUNT(*) FROM bank'\\\n",
    "                        Example:\\\n",
    "                        Find all employees that are unemployed\\\n",
    "                        SELECT * FROM bank WHERE job = 'unemployed'\"\n",
    "```\n",
    "\n",
    "```python\n",
    "prompt = f\"How does the author feel about this based on the statement {sentence}\\\n",
    "            'I find the user experience is confusing and convoluted'\\\n",
    "            Answer: Negative\\\n",
    "            'The decoration of the room made me feel welcome!'\\\n",
    "            Answer: Positive\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c64015",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting private LLMs (OpenAI API)</h1>\n",
    "\n",
    "\n",
    "We're going to focus on the `ChatCompletion` end point. \n",
    "\n",
    "Key elements:\n",
    "\n",
    "* OpenAI API Key\n",
    "* Model chosen (GPT4, GPT 3.5 Turbo, Text-Davinci)\n",
    "* Temperature\n",
    "* Your prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b78bf3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting private LLMs (OpenAI API)</h1>\n",
    "\n",
    "```python\n",
    "import openai\n",
    "\n",
    "class Prompter:\n",
    "    def __init__(self, api_key, gpt_model, temperature=0.2):\n",
    "        if not api_key:\n",
    "            raise Exception(\"Please provide the OpenAI API key\")\n",
    "\n",
    "        self.api_key  = api_key\n",
    "        self.gpt_model = gpt_model\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda4f5d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting private LLMs (OpenAI API)</h1>\n",
    "\n",
    "```python\n",
    "import openai\n",
    "\n",
    "class Prompter:\n",
    "    ...\n",
    "    def prompt_model_return(self, messages: list):\n",
    "        openai.api_key = self.api_key\n",
    "        response = openai.ChatCompletion.create(model=self.gpt_model, \n",
    "                                                messages=messages,\n",
    "                                                temperature=self.temperature)\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950ed4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Roles in prompting the ChatCompletion endpoint</h1>\n",
    "\n",
    "`system content`: What context should the LLM have in mind? Expert in marketing, helpful assistant, enthusiastic marketing generator.\n",
    "\n",
    "`user content`: What are typical requests that someone with that role would receive?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f916e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "import openai\n",
    "\n",
    "class Prompter:\n",
    "    ...\n",
    "    def natural_language_to_sql(self, db_name:str, schema:str, natural_question:str):\n",
    "\n",
    "            system_content = f\"You are a data analyst, \\\n",
    "                               and you specialize in solving business questions with SQL.\\\n",
    "                               You are given a natural language question, \\\n",
    "                               and your role is to translate the question\\\n",
    "                               into a query that can be executed against a database. \\\n",
    "                               Ensure your queries are written in a single line, with no special characters\"\n",
    "            \n",
    "            user_content = f\"Please generate a SQL query for data with in a database named {db_name}\\\n",
    "                            along with a schema {schema} for the question {natural_question}\"\n",
    "\n",
    "            full_prompts = [\n",
    "                                    {\"role\" : \"system\", \"content\" : system_content},\n",
    "                                    {\"role\" : \"user\", \"content\" : user_content},\n",
    "                                    ]\n",
    "\n",
    "            result = self.prompt_model_return(full_prompts)\n",
    "\n",
    "            return result\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde69af5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's suppose I have a database called `bank` that looks as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3d5a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%sqlcmd explore --table bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197e3d9f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's take the different prompting techniques for a ride.\n",
    "\n",
    "We will ask a GPT model to translate a natural language question into SQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4cc297",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm  = Prompter(open_ai_key, \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420334b0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Zero-shot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2e073",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_zero_shot(\"bank\", column_names, \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f4107",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_zero_shot(\"bank\", column_names, \"What is the total balance for employees by education?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84781b46",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Single-shot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018d103",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_single_shot(\"bank\", column_names, \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c7c68",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_single_shot(\"bank\", column_names, \"What is the total balance for employees by education?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e80111b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Few-shot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b386a3d4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_few_shot(\"bank\", column_names, \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d54dd4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_few_shot(\"bank\", column_names, \"What is the total balance for employees by education?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742bab4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Roles-based results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079af235",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_with_roles(\"bank\", column_names, \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8821c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_with_roles(\"bank\", column_names, \"What is the total balance for employees by education?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2aace6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT COUNT(DISTINCT job) FROM bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5666a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting open source LLMs through HuggingFace</h1>\n",
    "\n",
    "\n",
    "You need to ensure you install the right modules via `pip` along with the model card of the LLM.\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/hftasks.png\" width=\"1300px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "Example: https://huggingface.co/microsoft/tapex-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed22efa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>The reality of prompting open source models</h1>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/this-is-fine.jpeg\" width=\"1200px\"/>\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a3c86",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>The reality of prompting open source models</h1>\n",
    "\n",
    "* HuggingFace hosted models resemble GitHub repos (but not in a good way)\n",
    "* Dependency hell\n",
    "* Prompting results vary across different models and need to be highly adjusted\n",
    "* Adapt to whathever documentation the model card has\n",
    "* Higher likelihood you'll need to find the base model and fine-tune with your data for better results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a428c002",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "| Tranformer type | Architecture|Model-like | Focus | Example| \n",
    "|-|-|-|-|-|\n",
    "| Auto-regressive | Decoder-only |GPT-like | Generative tasks | Chat bot | \n",
    "| Auto-encoding | Encoder-only |BERT-like | Understanding of the input | Question-answering|\n",
    "| Sequence-to-Sequence |Encoder-decoder |BART/T5-like | Generative tasks that require an input | Language translation|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd58f99b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ba76cc8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> SELECT Balance FROM table WHERE Education = employee</s>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sql(query):\n",
    "    input_text = \"translate English to SQL: %s </s>\" % query\n",
    "    features = tokenizer([input_text], return_tensors='pt')\n",
    "\n",
    "    output = model.generate(input_ids=features['input_ids'], \n",
    "               attention_mask=features['attention_mask'])\n",
    "\n",
    "    return tokenizer.decode(output[0])\n",
    "\n",
    "# Translate\n",
    "natural_question =  \"What is the balance for employees by their education?\"\n",
    "prompt= f\"Translate English to SQL: {natural_question}\"  \n",
    "get_sql(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb94a639",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Intermission: Q & A about prompting</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd54bffe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Part II: Agents and open source frameworks</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2a7a97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>NLP pipelines and chaining</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0a5a2c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Core ideas</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f1eca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd2916f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Introducing Haystack</h1>\n",
    "\n",
    "- Call open source models\n",
    "- Build NLP pipelines with their custom built tools\n",
    "- Leverage their prompt templates\n",
    "- Incorporate Agents\n",
    "- Deploy via REST API\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a32ac5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Q & A about agents</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f48fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python-LLM",
   "language": "python",
   "name": "llm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
