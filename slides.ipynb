{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94275820",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "import transformers\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import banking  # noqa: E402\n",
    "from private_prompting import Prompter\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "open_ai_key = os.environ.get(\"openai-key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b54edc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Download data and initialize a DuckDB instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a3cb54",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "_ = banking.BankingData(\"https://tinyurl.com/jb-bank\", \"bank\")\n",
    "_.extract_to_csv()\n",
    "\n",
    "# Loading in SQL extension\n",
    "%reload_ext sql\n",
    "# Initiating a DuckDB database named 'bank.duck.db' to run our SQL queries on\n",
    "%sql duckdb:///bank.duck.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b58650",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Create table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cec2da1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>4521</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "|  4521 |\n",
       "+-------+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql CREATE OR REPLACE TABLE bank AS FROM read_csv_auto('bank_cleaned.csv', header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38077c4a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract column names\n",
    "columns = %sql PRAGMA table_info('bank');\n",
    "column_names = [row[1] for row in columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c18c8a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompts & Agents</h1>\n",
    "\n",
    "<h3 align='center'>How to incorporate prompting into your Python scripts and expand their functionality through agents</h3>\n",
    "\n",
    "<h4 align='center'>Laura Funderburk</h4>\n",
    "\n",
    "<h4 align='center'>PyData Vancouver</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b666908",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>About me</h2>\n",
    "\n",
    "* Developer Advocate @ Ploomber (talking and sharing knowledge about tools to improve the data science workflow)\n",
    "\n",
    "* Previously a data scientist (for-profit, not-for-profit sector)\n",
    "\n",
    "* Deeply curious about generative AI, Large Language Models, with a focus on engineering and automation\n",
    "\n",
    "* I use LLMs, prompting and agents to automate work tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80b748",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Talk at a glance</h2>\n",
    "\n",
    "<h3 align='center'>Part I: Prompting (40 minutes)</h3>\n",
    "\n",
    "\n",
    "1. LLMs use cases and tasks\n",
    "2. The Generative AI project lifecycle \n",
    "3. Choosing the right LLM architecture\n",
    "4. Key elements of prompting & prompting techniques\n",
    "5. Prompting private LLMs (OpenAI API): `ChatCompletion`\n",
    "6. Prompting open source LLMs through HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6bc99d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Talk at a glance</h2>\n",
    "\n",
    "<h3 align='center'>Part II: Agents and open source frameworks (20 minutes)</h3>\n",
    "\n",
    "1. What are agents\n",
    "2. Introduction to Haystack\n",
    "3. Introduction to LangChain\n",
    "4. Techniques to combine prompting and agents for deployment of applications\n",
    "5. Pros and cons of each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb9f5f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Part I: Prompting</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1f923",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>LLMs use cases and tasks</h2>\n",
    "\n",
    "\n",
    "* Text summarization\n",
    "\n",
    "* Conversation \n",
    "\n",
    "* Translation\n",
    "\n",
    "* Text generation\n",
    "\n",
    "* Text, token and sentiment classification\n",
    "\n",
    "* Table Q&A and Q&A from unstructured data\n",
    "\n",
    "* Sentence similarity\n",
    "\n",
    "* Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4370d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>LLMs use cases and tasks</h2>\n",
    "\n",
    "<h3 align='center'>Your goal is to understand the business case you are solving - then select the appropriate methods to solve it</h3>\n",
    "\n",
    "$\\Rightarrow$ Who will benefit from your product?\n",
    "\n",
    "$\\Rightarrow$ What are business constraints (time, data, resources)?\n",
    "\n",
    "$\\Rightarrow$ What is the end result?\n",
    "\n",
    "$\\Rightarrow$ How will it be served?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f2a51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>The generative AI project lifecycle</h2>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<center>\n",
    "  <img src=\"diagrams/genai_project_lifecycle.jpg\" width=\"1200px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "Source: Coursera, Generative AI with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ecc728",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Focus of this talk</h2>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/genai_project_lifecycle_focus.jpg\" width=\"1200px\"/>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68a8bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Choosing the right LLM (architecture)</h2>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/opt.jpeg\" width=\"200px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "* Decoder-only transformers: Good for **generative tasks** (auto-regressive)\n",
    "* Encoder-only transformers: Good for tasks that require **understanding of the input** (auto-encoding)\n",
    "* Encoder-decoder transformers or sequence-to-sequence models: Good for **generative tasks that require input** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0dfd13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Choosing the right LLM (architecture) </h2>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "| Tranformer type | Architecture|Model-like | Focus | Example| \n",
    "|-|-|-|-|-|\n",
    "| Auto-regressive | Decoder-only |GPT-like | Generative tasks | Chat bot | \n",
    "| Auto-encoding | Encoder-only |BERT-like | Understanding of the input | Question-answering|\n",
    "| Sequence-to-Sequence |Encoder-decoder |BART/T5-like | Generative tasks that require an input | Language translation|\n",
    "\n",
    "\n",
    "<p></p>\n",
    "\n",
    "[https://github.com/christianversloot/machine-learning-articles](https://github.com/christianversloot/machine-learning-articles/blob/main/differences-between-autoregressive-autoencoding-and-sequence-to-sequence-models-in-machine-learning.md)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939aeee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Do I need to train a new model to solve my problem?</h2>\n",
    "\n",
    "**No. Training an LLM is costly (GPU usage, time, compute, data). This is why sharing LLMs and their fine-tuned components has become highly popular.**\n",
    "\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/hftasks.png\" width=\"1200px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "You can start with prompting a LLM, then fine-tuning* if you aren't getting the results you want. You'll need to curate a dataset for this.\n",
    "\n",
    "*(instruction-tuning or, PEFT + LoRA for example)\n",
    "\n",
    "Source: https://huggingface.co/tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ef893",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c31ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Key elements of prompting</h2>\n",
    "\n",
    "<h3 align='center'>Basic</h3>\n",
    "\n",
    "* A LLM to interact with\n",
    "* Temperature\n",
    "* Max tokens\n",
    "* A natural language request\n",
    "\n",
    "<h3 align='center'>Advanced</h3>\n",
    "\n",
    "* Data (text files, web files)\n",
    "* A database storage system (vector DB, SQL, PostgreSQL, etc)\n",
    "* User interfaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c2b5e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Prompting techniques</h2>\n",
    "\n",
    "* Zero-shot inference\n",
    "\n",
    "* One-shot inference\n",
    "\n",
    "* Few-shot inference\n",
    "\n",
    "* Chain of thought \n",
    "\n",
    "* Roles (OpenAI API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c64015",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Prompting private LLMs (OpenAI API)</h2>\n",
    "\n",
    "\n",
    "We're going to focus on the `ChatCompletion` end point. \n",
    "\n",
    "Key elements:\n",
    "\n",
    "* OpenAI API Key\n",
    "* Model chosen (GPT4, GPT 3.5 Turbo, Text-Davinci)\n",
    "* Temperature\n",
    "* Your prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175457fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Prompting techniques: Zero-shot inference</h3>\n",
    "\n",
    "**Formula: instruction, no examples.**\n",
    "\n",
    "Suppose we want to translate a natural language question to SQL.\n",
    "\n",
    "```python\n",
    "prompt = f\"Answer the question {natural_question} \\\n",
    "           for table {db_name} \\\n",
    "           with schema {schema}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5554f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Prompting techniques: One-shot inference</h3>\n",
    "\n",
    "**Formula: instruction, one example.**\n",
    "\n",
    "\n",
    "```python\n",
    "prompt = f\"Answer the question {natural_question} \\\n",
    "           for table {db_name} \\\n",
    "           with schema {schema}\\\n",
    "               Question: How many records are there?\\\n",
    "               Answer: SELECT COUNT(*) FROM bank\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db916187",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Prompting techniques: Few-shot inference</h3>\n",
    "\n",
    "**Formula: instruction, more than one example.**\n",
    "\n",
    "```python\n",
    "prompt= f\"Answer the question {natural_question} \\\n",
    "           for table {db_name} \\\n",
    "           with schema {schema}\\\n",
    "            Question: How many records are there?\\\n",
    "            Answer: SELECT COUNT(*) FROM bank\\\n",
    "            Question: Find all employees that are unemployed\\\n",
    "            Answer: SELECT * FROM bank WHERE job = 'unemployed'\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950ed4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Roles in prompting the ChatCompletion endpoint (OpenAI API only)</h3>\n",
    "\n",
    "The 'role' can take one of three values: `system`, `user` or the `assistant`\n",
    "\n",
    "The `content` contains the text of the message from the role. \n",
    "\n",
    "`system` role: You can use a system level instruction to guide your model's behavior throughout the conversation. \n",
    "\n",
    "`user` role: What are typical requests that someone in that role would receive?\n",
    "\n",
    "`assistant` role: This role  represents the language model, such as ChatGPT, which generates responses based on the provided user messages.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ea08d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Business problem: translate natural language questions into SQL</h2>\n",
    "\n",
    "We can solve this problem with prompting and the `ChatCompletion` endpoint on the OpenAI API.\n",
    "\n",
    "**Approach: build a Prompter class and add each prompting technique as a method, then evaluate results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b78bf3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Approach: initialize a Prompter class</h3>\n",
    "\n",
    "```python\n",
    "import openai\n",
    "\n",
    "class Prompter:\n",
    "    def __init__(self, api_key, gpt_model, temperature=0.2):\n",
    "        if not api_key:\n",
    "            raise Exception(\"Please provide the OpenAI API key\")\n",
    "\n",
    "        self.api_key  = api_key\n",
    "        self.gpt_model = gpt_model\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    \n",
    "```\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cdda4f5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Approach: add a chat completion method to call a GPT-like model (OpenAI API)</h3>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/init-chatcompletion.png\" width=\"1200px\"/>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a14e28e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Approach: add a method with a single-shot prompt and the assistant role</h3>\n",
    "\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/prompt-roles-assistant.png\" width=\"1200px\"/>\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a40f916e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Approach: add a method with a system and user roles</h3>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/prompt-roles-sql.png\" width=\"1200px\"/>\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde69af5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Evaluate results</h2>\n",
    "\n",
    "\n",
    "Let's suppose I have a DuckDB in-memory instance with a table called `bank` that looks as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3d5a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%sqlcmd explore --table bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197e3d9f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Evaluate results</h2>\n",
    "\n",
    "Let's take the different prompting techniques for a ride.\n",
    "\n",
    "We will ask the OpenAI API GPT-3.5-turbo model to translate a natural language question into SQL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4cc297",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm  = Prompter(open_ai_key, \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420334b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Zero-shot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eb2e073",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To determine the number of unique jobs in the table, we need to look at the 'job' column. We can use the DISTINCT keyword in SQL to get the unique values in that column. Here is an example SQL query to find the number of unique jobs:\\n\\nSELECT COUNT(DISTINCT job) AS unique_jobs\\nFROM bank;\\n\\nThis query will return the count of unique jobs in the 'job' column of the 'bank' table.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.natural_language_zero_shot(\"bank\", \n",
    "                              column_names, \n",
    "                              \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "988f4107",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To find the total balance for employees by education, we need to group the data by the 'education' column and calculate the sum of the 'balance' column for each group. Here is the SQL query to achieve this:\\n\\nSELECT education, SUM(balance) AS total_balance\\nFROM bank\\nGROUP BY education;\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.natural_language_zero_shot(\"bank\", \n",
    "                              column_names, \n",
    "                              \"What is the total balance for \\\n",
    "                               employees by education?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84781b46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Single-shot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f018d103",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 45211 records in the bank table.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.natural_language_single_shot(\"bank\", \n",
    "                                column_names, \n",
    "                                \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "742c7c68",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 45211 records in the bank table.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.natural_language_single_shot(\"bank\", \n",
    "                                column_names, \n",
    "                                \"What is the total balance for \\\n",
    "                                employees by education?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742bab4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Roles-based results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079af235",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(DISTINCT job) FROM bank'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.natural_language_with_roles(\"bank\", \n",
    "                               column_names, \n",
    "                               \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa8821c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT education, SUM(balance) AS total_balance FROM bank GROUP BY education'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.natural_language_with_roles(\"bank\", \n",
    "                               column_names, \n",
    "                               \"What is the total balance for\\\n",
    "                               employees by education?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b2aace6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>education</th>\n",
       "            <th>total_balance</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>primary</td>\n",
       "            <td>957027</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>secondary</td>\n",
       "            <td>2759854</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>tertiary</td>\n",
       "            <td>2396822</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>unknown</td>\n",
       "            <td>318133</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----------+---------------+\n",
       "| education | total_balance |\n",
       "+-----------+---------------+\n",
       "|  primary  |     957027    |\n",
       "| secondary |    2759854    |\n",
       "|  tertiary |    2396822    |\n",
       "|  unknown  |     318133    |\n",
       "+-----------+---------------+"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT education, SUM(balance) AS total_balance \n",
    "FROM bank GROUP BY education;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5666a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Prompting open source LLMs through HuggingFace</h3>\n",
    "\n",
    "\n",
    "You need to ensure you install the right modules via `pip` along with any moduyles specified in the model card of the LLM.\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/hftasks.png\" width=\"800px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "Example: https://huggingface.co/microsoft/tapex-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3868107",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>The reality of prompting open source models</h3>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/this-is-fine.jpeg\" width=\"600px\"/>\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65aa906",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>The reality of prompting open source models</h3>\n",
    "\n",
    "* HuggingFace hosted models resemble GitHub repos (but not in a good way).\n",
    "* You will need to feel comfortable using the `transformers`, `PyTorch` and `TensorFlow` libraries.\n",
    "* You will need a bit more than just comfort with the transformer architectures.\n",
    "* Dependency hell.\n",
    "* Prompting results vary across different models.\n",
    "* Model documentation ranges from non-existent to highly technical (research papers).\n",
    "* Higher likelihood that you'll need to find the base model and fine-tune with your data for better results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcce9b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Prompting a T5-like model to translate NL to SQL</h3>\n",
    "\n",
    "We will explore the functionality of the T5-like fine-tuned model `mrm8488/t5-base-finetuned-wikiSQL`.\n",
    "\n",
    "Remember that T5-like models are of type encoder-decoder and good at translating between languages.\n",
    "\n",
    "This model was fine-tuned on the `wiki-SQL` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb907a40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "```python\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd8bedc4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "/Users/macpro/anaconda3/envs/llm-env/lib/python3.10/site-packages/transformers/models/auto/modeling_auto.py:1362: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b84aeff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<pad> SELECT COUNT Table FROM table WHERE Schema = ['age', 'job','marital', 'education', 'default', 'balance', 'housing', 'loan', 'contact', 'day','month', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'y</s>\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_sql(query):\n",
    "    input_text = \"translate English to SQL: %s </s>\" % query\n",
    "    features = tokenizer([input_text], \n",
    "                         return_tensors='pt')\n",
    "\n",
    "    output = model.generate(input_ids=features['input_ids'], \n",
    "                           attention_mask=features['attention_mask'],\n",
    "                            max_new_tokens=200)\n",
    "\n",
    "    return tokenizer.decode(output[0])\n",
    "\n",
    "# Translate\n",
    "natural_question = \"How many entries are there?\" \n",
    "db_name = \"banks\"\n",
    "schema = column_names\n",
    "\n",
    "prompt = f\"{natural_question} \\\n",
    "           for table {db_name} \\\n",
    "           with schema {schema}\"\n",
    "\n",
    "get_sql(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de1ce9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>How to guide your choices</h3>\n",
    "\n",
    "1. Remember your use case, the business constraints and who will use your application\n",
    "2. Remember the three base models and their keywords\n",
    "3. Be ready for the possibility of fine-tuning\n",
    "\n",
    "<p> </p>\n",
    "\n",
    "| Tranformer type | Architecture|Model-like | Focus | Example| \n",
    "|-|-|-|-|-|\n",
    "| Auto-regressive | Decoder-only |GPT-like | Generative tasks | Chat bot | \n",
    "| Auto-encoding | Encoder-only |BERT-like | Understanding of the input | Question-answering|\n",
    "| Sequence-to-Sequence |Encoder-decoder |BART/T5-like | Generative tasks that require an input | Language translation|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121dcfb7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Part II: Agents and open source frameworks</h1>\n",
    "\n",
    "We will now turn our attention to two open-source frameworks you can use to augment the functionality of prompting through agents: LangChain and Haystack. \n",
    "\n",
    "The frameworks introduced here can both be installed via `pip` and imported as modules into your Python script. \n",
    "\n",
    "Both of them offer agents, although they approach the implementation differently. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6c9813",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>What are agents</h2>\n",
    "\n",
    "The role of an agent is to empower LLMs to decide which actions to take, thereby granting them a certain degree of autonomy. In simple terms, agents are a fusion of LLM chains (which are sequences of LLMs) and tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b7b0b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Introducing LangChain</h2>\n",
    "<center>\n",
    "  <img src=\"diagrams/langchain.png\" width=\"300px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "LangChain is a framework for developing applications powered by language models. It enables applications that are:\n",
    "\n",
    "* Data-aware: connect a language model to other sources of data\n",
    "\n",
    "* Agentic: allow a language model to interact with its environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5624e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>How does LangChain approach Agents?</h2>\n",
    "\n",
    "<p> </p>\n",
    "\n",
    "<center>\n",
    "  <img src=\"diagrams/langchain.jpg\" width=\"1200px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "With `LangChain` we think in terms of **components** and **off-the-shelf chains**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283a276a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>How to incorporate it into your scripts</h2>\n",
    "\n",
    "You can build your custom functions in Python and use their `@tool` decorator. Then after initializing LangChain along with the GPT model you want, you can then ask it to perform tasks with natural language commands. \n",
    "\n",
    "**Mini-demo time.**\n",
    "\n",
    "Tools the agent was given:\n",
    "\n",
    "1. A web scraper\n",
    "2. A GPT based prompter with `system` and `user` content\n",
    "3. Instructions to summarize the webpage and then write a social media post about the summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d9284a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Introducing Haystack</h2>\n",
    "<center>\n",
    "  <img src=\"diagrams/haystack-ogimage.png\" width=\"500px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "Haystack is an open-source framework for building search systems that work intelligently over large document collections.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab967c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Functionality:\n",
    "\n",
    "- Call open source models, hosted models (Azure, AWS) as well as private ones (OpenAI API)\n",
    "- Build production-ready NLP pipelines with their custom-built tools\n",
    "- Machinery for unstructured data processing (text)\n",
    "- Leverage their prompt templates ([prompt-hub](https://prompthub.deepset.ai/))\n",
    "- Incorporate Agents\n",
    "- Compatibility with Vector and classic DB.\n",
    "- Deploy via REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2916f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>How does Haystack approach Agents?</h2>\n",
    "\n",
    "\n",
    "They rely heavily on the use of **prompt nodes**,  the **pipelines** that connect them, AND THEN expand their functionality through **agents** and **tools**.\n",
    "\n",
    "\n",
    "**Nodes**: each Node achieves one thing (preprocessing documents, retrieving documents, using language models to answer questions and so on)\n",
    "\n",
    "**Pipelines**: this is the standard Haystack structure that can connect to your data and perform on it NLP tasks that you define. \n",
    "\n",
    "**Tools**: you can think of a Tool as an expert, that is able to do something really well. Such as a calculator, good at mathematics. \n",
    "\n",
    "**Agent**: a component that is powered by an LLM, such as GPT-3. It can decide on the next best course of action so as to get to the result of a query. It uses the Tools available to it to achieve this. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f9a5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Creating a custom node to perform SQL queries in Jupyter</h2>\n",
    "\n",
    "We are going to use `JupySQL` to perform the quries. \n",
    "\n",
    "`JupySQL` was developed on top of iPython-SQL and its purpose is to connect to DBs of various flavours and execute queries. \n",
    "\n",
    "This will be our **tool** `JupySQLQuery` and we will define it as a subclass of the `BaseComponent` class in Haystack.\n",
    "\n",
    "We will also create a prompt with detailed instructions for how the agent should respond to different situations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e27eb4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "  <img src=\"diagrams/JupySQL-agent.png\" width=\"500px\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a652343a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes.base import BaseComponent\n",
    "\n",
    "class JupySQLQuery(BaseComponent):\n",
    "    outgoing_edges = 1\n",
    "    \n",
    "    def __init__(self):\n",
    "        %reload_ext sql\n",
    "        %sql duckdb:///bank.duck.db\n",
    "\n",
    "    def run(self, query: str):\n",
    "        result = %sql {{query}}\n",
    "        output = {\n",
    "            \"results\":  f\"{result}\",\n",
    "            \"query\": query,\n",
    "            \n",
    "        }\n",
    "        return output\n",
    "\n",
    "    def run_batch(self, queries: list):\n",
    "        results = []\n",
    "        for query in queries:\n",
    "            result = %sql {query}\n",
    "            output = {\n",
    "                \"results\":  f\"{result}\",\n",
    "                \"query\": query,\n",
    "            }\n",
    "            results.append(output)\n",
    "        return results\n",
    "\n",
    "    \n",
    "jupy_sql_query = JupySQLQuery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "332677e6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from haystack.agents import Tool\n",
    "from haystack.nodes import PromptNode\n",
    "from jupysqlagent import sql_agent_prompt\n",
    "from haystack.agents import Agent, Tool\n",
    "\n",
    "jupy_sql_query_tool = Tool(name=\"JupySQL_Query\", \n",
    "                           pipeline_or_node=jupy_sql_query, \n",
    "                           description=\"\"\"This tool is useful for consuming SQL queries \\\n",
    "                                        and responds with the result\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0c44ead",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get the API key\n",
    "openai_api_key = os.environ.get(\"openai-key\")\n",
    "chosen_model = \"gpt-4\"\n",
    "\n",
    "\n",
    "# Define a prompt node that uses the GPT-4 model\n",
    "prompt_node = PromptNode(model_name_or_path=chosen_model, \n",
    "                         api_key=openai_api_key, \n",
    "                         stop_words=[\"Observation:\"], \n",
    "                         max_length=1000)\n",
    "\n",
    "# Define the agent\n",
    "agent = Agent(prompt_node=prompt_node, \n",
    "              prompt_template=sql_agent_prompt)\n",
    "\n",
    "agent.add_tool(jupy_sql_query_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c928e3c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent custom-at-query-time started with {'query': 'How many records are there', 'params': None}\n",
      "\u001b[32mcount\u001b[0m\u001b[32m the\u001b[0m\u001b[32m total\u001b[0m\u001b[32m number\u001b[0m\u001b[32m of\u001b[0m\u001b[32m records\u001b[0m\u001b[32m in\u001b[0m\u001b[32m the\u001b[0m\u001b[32m '\u001b[0m\u001b[32mbank\u001b[0m\u001b[32m'\u001b[0m\u001b[32m table\u001b[0m\u001b[32m.\u001b[0m\u001b[32m To\u001b[0m\u001b[32m do\u001b[0m\u001b[32m this\u001b[0m\u001b[32m,\u001b[0m\u001b[32m I\u001b[0m\u001b[32m can\u001b[0m\u001b[32m use\u001b[0m\u001b[32m the\u001b[0m\u001b[32m SQL\u001b[0m\u001b[32m count\u001b[0m\u001b[32m function\u001b[0m\u001b[32m.\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m J\u001b[0m\u001b[32mupy\u001b[0m\u001b[32mSQL\u001b[0m\u001b[32m_Query\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m select\u001b[0m\u001b[32m count\u001b[0m\u001b[32m(*)\u001b[0m\u001b[32m from\u001b[0m\u001b[32m bank\u001b[0m\u001b[32m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: \u001b[33m+--------------+\n",
      "| count_star() |\n",
      "+--------------+\n",
      "|     4521     |\n",
      "+--------------+\u001b[0m\n",
      "Thought: \u001b[32mThe\u001b[0m\u001b[32m count\u001b[0m\u001b[32m function\u001b[0m\u001b[32m in\u001b[0m\u001b[32m SQL\u001b[0m\u001b[32m returns\u001b[0m\u001b[32m the\u001b[0m\u001b[32m total\u001b[0m\u001b[32m number\u001b[0m\u001b[32m of\u001b[0m\u001b[32m records\u001b[0m\u001b[32m in\u001b[0m\u001b[32m the\u001b[0m\u001b[32m '\u001b[0m\u001b[32mbank\u001b[0m\u001b[32m'\u001b[0m\u001b[32m table\u001b[0m\u001b[32m.\n",
      "\u001b[0m\u001b[32mFinal\u001b[0m\u001b[32m Answer\u001b[0m\u001b[32m:\u001b[0m\u001b[32m There\u001b[0m\u001b[32m are\u001b[0m\u001b[32m \u001b[0m\u001b[32m452\u001b[0m\u001b[32m1\u001b[0m\u001b[32m records\u001b[0m\u001b[32m in\u001b[0m\u001b[32m the\u001b[0m\u001b[32m table\u001b[0m\u001b[32m.\u001b[0m"
     ]
    }
   ],
   "source": [
    "result = agent.run(\"How many records are there\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d8664a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent custom-at-query-time started with {'query': 'How many unique levels of education are there', 'params': None}\n",
      "\u001b[32midentify\u001b[0m\u001b[32m the\u001b[0m\u001b[32m unique\u001b[0m\u001b[32m values\u001b[0m\u001b[32m in\u001b[0m\u001b[32m the\u001b[0m\u001b[32m '\u001b[0m\u001b[32meducation\u001b[0m\u001b[32m'\u001b[0m\u001b[32m column\u001b[0m\u001b[32m from\u001b[0m\u001b[32m the\u001b[0m\u001b[32m '\u001b[0m\u001b[32mbank\u001b[0m\u001b[32m'\u001b[0m\u001b[32m table\u001b[0m\u001b[32m.\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m J\u001b[0m\u001b[32mupy\u001b[0m\u001b[32mSQL\u001b[0m\u001b[32m_Query\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m select\u001b[0m\u001b[32m distinct\u001b[0m\u001b[32m education\u001b[0m\u001b[32m from\u001b[0m\u001b[32m bank\u001b[0m\u001b[32m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: \u001b[33m+-----------+\n",
      "| education |\n",
      "+-----------+\n",
      "|  primary  |\n",
      "| secondary |\n",
      "|  tertiary |\n",
      "|  unknown  |\n",
      "+-----------+\u001b[0m\n",
      "Thought: \u001b[32mThe\u001b[0m\u001b[32m query\u001b[0m\u001b[32m has\u001b[0m\u001b[32m been\u001b[0m\u001b[32m successfully\u001b[0m\u001b[32m resolved\u001b[0m\u001b[32m using\u001b[0m\u001b[32m the\u001b[0m\u001b[32m SQL\u001b[0m\u001b[32m query\u001b[0m\u001b[32m which\u001b[0m\u001b[32m gives\u001b[0m\u001b[32m us\u001b[0m\u001b[32m the\u001b[0m\u001b[32m unique\u001b[0m\u001b[32m levels\u001b[0m\u001b[32m of\u001b[0m\u001b[32m education\u001b[0m\u001b[32m present\u001b[0m\u001b[32m in\u001b[0m\u001b[32m the\u001b[0m\u001b[32m bank\u001b[0m\u001b[32m table\u001b[0m\u001b[32m.\n",
      "\u001b[0m\u001b[32mFinal\u001b[0m\u001b[32m Answer\u001b[0m\u001b[32m:\u001b[0m\u001b[32m There\u001b[0m\u001b[32m are\u001b[0m\u001b[32m four\u001b[0m\u001b[32m unique\u001b[0m\u001b[32m levels\u001b[0m\u001b[32m of\u001b[0m\u001b[32m education\u001b[0m\u001b[32m in\u001b[0m\u001b[32m the\u001b[0m\u001b[32m bank\u001b[0m\u001b[32m:\u001b[0m\u001b[32m '\u001b[0m\u001b[32mprimary\u001b[0m\u001b[32m',\u001b[0m\u001b[32m '\u001b[0m\u001b[32msecondary\u001b[0m\u001b[32m',\u001b[0m\u001b[32m '\u001b[0m\u001b[32mter\u001b[0m\u001b[32mti\u001b[0m\u001b[32mary\u001b[0m\u001b[32m',\u001b[0m\u001b[32m and\u001b[0m\u001b[32m '\u001b[0m\u001b[32munknown\u001b[0m\u001b[32m'.\u001b[0m"
     ]
    }
   ],
   "source": [
    "result = agent.run(\"How many unique levels of education are there\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc87debc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent custom-at-query-time started with {'query': 'How many unique levels of education are there,                     what is the average employee age? ', 'params': None}\n",
      "\u001b[32mfind\u001b[0m\u001b[32m out\u001b[0m\u001b[32m how\u001b[0m\u001b[32m many\u001b[0m\u001b[32m unique\u001b[0m\u001b[32m levels\u001b[0m\u001b[32m of\u001b[0m\u001b[32m education\u001b[0m\u001b[32m there\u001b[0m\u001b[32m are\u001b[0m\u001b[32m,\u001b[0m\u001b[32m and\u001b[0m\u001b[32m then\u001b[0m\u001b[32m I\u001b[0m\u001b[32m need\u001b[0m\u001b[32m to\u001b[0m\u001b[32m find\u001b[0m\u001b[32m out\u001b[0m\u001b[32m the\u001b[0m\u001b[32m average\u001b[0m\u001b[32m age\u001b[0m\u001b[32m of\u001b[0m\u001b[32m the\u001b[0m\u001b[32m employees\u001b[0m\u001b[32m.\u001b[0m\u001b[32m \n",
      "\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m J\u001b[0m\u001b[32mupy\u001b[0m\u001b[32mSQL\u001b[0m\u001b[32m_Query\u001b[0m\u001b[32m \n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m select\u001b[0m\u001b[32m count\u001b[0m\u001b[32m(dist\u001b[0m\u001b[32minct\u001b[0m\u001b[32m education\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as\u001b[0m\u001b[32m unique\u001b[0m\u001b[32m_\u001b[0m\u001b[32meducation\u001b[0m\u001b[32m_levels\u001b[0m\u001b[32m from\u001b[0m\u001b[32m bank\u001b[0m\u001b[32m;\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: \u001b[33m+-------------------------+\n",
      "| unique_education_levels |\n",
      "+-------------------------+\n",
      "|            4            |\n",
      "+-------------------------+\u001b[0m\n",
      "Thought: \u001b[32mThere\u001b[0m\u001b[32m are\u001b[0m\u001b[32m \u001b[0m\u001b[32m4\u001b[0m\u001b[32m unique\u001b[0m\u001b[32m levels\u001b[0m\u001b[32m of\u001b[0m\u001b[32m education\u001b[0m\u001b[32m in\u001b[0m\u001b[32m the\u001b[0m\u001b[32m bank\u001b[0m\u001b[32m's\u001b[0m\u001b[32m database\u001b[0m\u001b[32m.\u001b[0m\u001b[32m Now\u001b[0m\u001b[32m,\u001b[0m\u001b[32m let\u001b[0m\u001b[32m's\u001b[0m\u001b[32m find\u001b[0m\u001b[32m out\u001b[0m\u001b[32m the\u001b[0m\u001b[32m average\u001b[0m\u001b[32m age\u001b[0m\u001b[32m of\u001b[0m\u001b[32m the\u001b[0m\u001b[32m employees\u001b[0m\u001b[32m.\n",
      "\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m J\u001b[0m\u001b[32mupy\u001b[0m\u001b[32mSQL\u001b[0m\u001b[32m_Query\u001b[0m\u001b[32m \n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m select\u001b[0m\u001b[32m avg\u001b[0m\u001b[32m(age\u001b[0m\u001b[32m)\u001b[0m\u001b[32m as\u001b[0m\u001b[32m average\u001b[0m\u001b[32m_age\u001b[0m\u001b[32m from\u001b[0m\u001b[32m bank\u001b[0m\u001b[32m;\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: \u001b[33m+-------------------+\n",
      "|    average_age    |\n",
      "+-------------------+\n",
      "| 41.17009511170095 |\n",
      "+-------------------+\u001b[0m\n",
      "Thought: \u001b[32mThe\u001b[0m\u001b[32m average\u001b[0m\u001b[32m age\u001b[0m\u001b[32m of\u001b[0m\u001b[32m the\u001b[0m\u001b[32m employees\u001b[0m\u001b[32m in\u001b[0m\u001b[32m the\u001b[0m\u001b[32m bank\u001b[0m\u001b[32m's\u001b[0m\u001b[32m database\u001b[0m\u001b[32m is\u001b[0m\u001b[32m approximately\u001b[0m\u001b[32m \u001b[0m\u001b[32m41\u001b[0m\u001b[32m.\u001b[0m\u001b[32m17\u001b[0m\u001b[32m years\u001b[0m\u001b[32m old\u001b[0m\u001b[32m.\n",
      "\u001b[0m\u001b[32mFinal\u001b[0m\u001b[32m Answer\u001b[0m\u001b[32m:\u001b[0m\u001b[32m There\u001b[0m\u001b[32m are\u001b[0m\u001b[32m \u001b[0m\u001b[32m4\u001b[0m\u001b[32m unique\u001b[0m\u001b[32m levels\u001b[0m\u001b[32m of\u001b[0m\u001b[32m education\u001b[0m\u001b[32m and\u001b[0m\u001b[32m the\u001b[0m\u001b[32m average\u001b[0m\u001b[32m age\u001b[0m\u001b[32m of\u001b[0m\u001b[32m the\u001b[0m\u001b[32m employees\u001b[0m\u001b[32m is\u001b[0m\u001b[32m approximately\u001b[0m\u001b[32m \u001b[0m\u001b[32m41\u001b[0m\u001b[32m.\u001b[0m\u001b[32m17\u001b[0m\u001b[32m years\u001b[0m\u001b[32m old\u001b[0m\u001b[32m.\u001b[0m"
     ]
    }
   ],
   "source": [
    "result = agent.run(\"How many unique levels of education are there, \\\n",
    "                    what is the average employee age? \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b210a92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>LangChain Pros & Cons</h3>\n",
    "\n",
    "**Pros**\n",
    "1. Easy to get started with\n",
    "2. Maps easily to OpenAI API chat completion end point\n",
    "3. Can easily connect to a variety of applications based on your function definition\n",
    "\n",
    "**Cons**\n",
    "1. Security concerns\n",
    "2. Evaluation of results \n",
    "3. Deployment \n",
    "4. Integration to open LLMs and hosted LLMs seems to be in early stages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5ba266",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Haystack Pros & Cons</h3>\n",
    "\n",
    "**Pros**\n",
    "1. Established framework with a focus on production-ready NLP applications\n",
    "2. Constantly adapting to new changes and building on top of their framework\n",
    "3. Deployment-friendly\n",
    "4. Offers solutions for your custom documents and access to a variety of database flavours\n",
    "5. Offers prompt templates\n",
    "\n",
    "**Cons**\n",
    "1. Steeper learning curve\n",
    "2. Current deployment option is REST API, but other options currently not available\n",
    "3. Limitations on the types of files it can handle (PDF and markdown currently not supported) \n",
    "4. Narrower focus when it comes to the types of agents it supports (although you can create custom agents, through custom nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d290e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Final thoughts</h1>\n",
    "\n",
    "* Prompt-engineering starts with a well defined project and a clear choice of transformer architecture\n",
    "* Prompting is usually the first step when using an LLM\n",
    "* Prompting via the OpenAI API provides a quick solution to prototype, but has limitations when it comes to private data/documents\n",
    "* Prompting open source LLMs requires understanding of transformer architecture and openness to fine-tune \n",
    "* We explored two open source frameworks that allow you to augment the funcionality of LLMs via agents\n",
    "* LangChain approaches agents through **components** and **chains**\n",
    "* Haystack approaches agents in terms of expanding the funcionality of **prompt nodes**, **pipelines** and a **document store**."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python-LLM",
   "language": "python",
   "name": "llm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
