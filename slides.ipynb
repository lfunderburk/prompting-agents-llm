{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94275820",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "import transformers\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import banking  # noqa: E402\n",
    "from private_prompting import Prompter\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "open_ai_key = os.environ.get(\"openai-key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db6b656",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "_ = banking.BankingData(\"https://tinyurl.com/jb-bank\", \"bank\")\n",
    "_.extract_to_csv()\n",
    "\n",
    "# Loading in SQL extension\n",
    "%reload_ext sql\n",
    "# Initiating a DuckDB database named 'bank.duck.db' to run our SQL queries on\n",
    "%sql duckdb:///bank.duck.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7b48f37",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>4521</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "|  4521 |\n",
       "+-------+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TABLE bank AS\n",
    "FROM read_csv_auto('bank_cleaned.csv', header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e47f61b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = %sql PRAGMA table_info('bank');\n",
    "\n",
    "# Extract column names\n",
    "column_names = [row[1] for row in columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c18c8a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompts & Agents</h1>\n",
    "\n",
    "<h2 align='center'>How to incorporate prompting into your Python scripts <br>and expand their functionality through agents</h2>\n",
    "\n",
    "<h2 align='center'>Laura Funderburk</h2>\n",
    "\n",
    "<h2 align='center'>PyData Vancouver</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80b748",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Talk at a glance</h1>\n",
    "\n",
    "<h2 align='center'>Part I: Prompting (25 minutes)</h2>\n",
    "\n",
    "\n",
    "1. LLMs use cases and tasks\n",
    "2. The Generative AI project lifecycle \n",
    "3. Choosing the right LLM for the desired task\n",
    "4. Key elements of prompting & Prompting techniques\n",
    "5. Prompting private LLMs (OpenAI API): `ChatCompletion`\n",
    "6. Prompting open source LLMs through HuggingFace\n",
    "\n",
    "\n",
    "Q&A about prompting (5 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6bc99d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Talk at a glance</h1>\n",
    "\n",
    "<h2 align='center'>Part II: Incorporating agents (25 minutes)</h2>\n",
    "\n",
    "\n",
    "1. (Some) Applications of agents\n",
    "2. Introduction to Haystack\n",
    "3. Introduction to LangChain\n",
    "4. Which one to pick\n",
    "5. Techniques to combine prompting and agents\n",
    "\n",
    "Q&A about agents (5 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1efe1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>LLMs use cases and tasks</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1f923",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>LLMs use cases and tasks</h1>\n",
    "\n",
    "\n",
    "* Text summarization\n",
    "\n",
    "* Conversation \n",
    "\n",
    "* Translation\n",
    "\n",
    "* Text generation\n",
    "\n",
    "* Text, token and sentiment classification\n",
    "\n",
    "* Table Q&A and Q&A from unstructured data\n",
    "\n",
    "* Sentence similarity\n",
    "\n",
    "* Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4370d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>LLMs use cases and tasks</h1>\n",
    "\n",
    "<h2 align='center'>Your goal is to understand the business case you are solving -<br> then select the appropriate methods to solve it</h2>\n",
    "\n",
    "<h3 align='center'>Who will benefit from your product?</h3>\n",
    "\n",
    "<h3 align='center'>What is the end result?</h3>\n",
    "\n",
    "<h3 align='center'>How will it be served?</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f6595",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>The generative AI project lifecycle</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f2a51",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>The generative AI project lifecycle</h1>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<center>\n",
    "  <img src=\"diagrams/genai_project_lifecycle.jpg\" width=\"1400px\"/>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ecc728",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Focus of this talk</h1>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/genai_project_lifecycle_focus.jpg\" width=\"1400px\"/>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68a8bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Choosing the right LLM (architecture) for the desired task</h1>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/opt.jpeg\" width=\"200px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "* GPT-like (also called auto-regressive Transformer models)\n",
    "* BERT-like (also called auto-encoding Transformer models)\n",
    "* BART/T5-like (also called sequence-to-sequence Transformer models)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0dfd13",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Choosing the right LLM (architecture) for the desired task</h1>\n",
    "\n",
    "* Encoder-only models: Good for tasks that require **understanding of the input** \n",
    "* Decoder-only models: Good for **generative tasks** \n",
    "* Encoder-decoder models or sequence-to-sequence models: Good for **generative tasks that require an input** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939aeee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Do I need to train a new model to solve my problem?</h1>\n",
    "\n",
    "<h3 align='center'>No. Training a LLM is costly (GPU usage, time, resources, data). This is why sharing LLMs and their fine-tuned componets has become highly popularized.</h3>\n",
    "\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/hftasks.png\" width=\"1300px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "Source: https://huggingface.co/tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c31ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Key elements of prompting</h1>\n",
    "\n",
    "<h3 align='center'>Basic</h3>\n",
    "\n",
    "* A LLM to interact with\n",
    "* Temperature\n",
    "* Max tokens\n",
    "* A natural language request\n",
    "\n",
    "<h3 align='center'>Advanced</h3>\n",
    "\n",
    "* Data (text files, web files)\n",
    "* A database storage system (vector DB, SQL, PostgreSQL, etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c2b5e7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting techniques</h1>\n",
    "\n",
    "* Zero-shot inference\n",
    "\n",
    "* One-shot inference\n",
    "\n",
    "* Few-shot inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175457fa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting techniques: Zero-shot inference</h1>\n",
    "\n",
    "Formula: prompt, no examples.\n",
    "\n",
    "Suppose we want to translate natural language queries into SQL. \n",
    "\n",
    "We have a `natural_question`, a database table name `db_name` and a schema `schema`\n",
    "\n",
    "```python\n",
    "prompt= f\"Answer the question {natural_question} for table {db_name} with schema {schema}\"        \n",
    "```\n",
    "\n",
    "Suppose we want to classify the sentiment in a sentence `sentence`\n",
    "\n",
    "```python\n",
    "prompt = f\"How does the author feel about this based on the statement {sentence}\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5554f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting techniques: One-shot inference</h1>\n",
    "\n",
    "Formula: prompt, one example.\n",
    "\n",
    "```python\n",
    "prompt= f\"Answer the question {natural_question} for table {db_name} with schema {schema}\\\n",
    "                        For example, if you receive the question: 'How many records are there?'\\\n",
    "                        An appropriate answer is\\\n",
    "                        'SELECT COUNT(*) FROM bank'\"\n",
    "```\n",
    "\n",
    "```python\n",
    "prompt = f\"How does the author feel about this based on the statement {sentence}\\\n",
    "            'I find the user experience is confusing and convoluted'\\\n",
    "            Answer: Negative\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db916187",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting techniques: Few-shot inference</h1>\n",
    "\n",
    "More than one example.\n",
    "\n",
    "```python\n",
    "prompt= f\"Answer the question {natural_question} for table {db_name} with schema {schema}\\\n",
    "                        Example:\\\n",
    "                        'How many records are there?'\\\n",
    "                        'SELECT COUNT(*) FROM bank'\\\n",
    "                        Example:\\\n",
    "                        Find all employees that are unemployed\\\n",
    "                        SELECT * FROM bank WHERE job = 'unemployed'\"\n",
    "```\n",
    "\n",
    "```python\n",
    "prompt = f\"How does the author feel about this based on the statement {sentence}\\\n",
    "            'I find the user experience is confusing and convoluted'\\\n",
    "            Answer: Negative\\\n",
    "            'The decoration of the room made me feel welcome!'\\\n",
    "            Answer: Positive\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c64015",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting private LLMs (OpenAI API)</h1>\n",
    "\n",
    "\n",
    "We're going to focus on the `ChatCompletion` end point. \n",
    "\n",
    "Key elements:\n",
    "\n",
    "* OpenAI API Key\n",
    "* Model chosen (GPT4, GPT 3.5 Turbo, Text-Davinci)\n",
    "* Temperature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b78bf3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting private LLMs (OpenAI API)</h1>\n",
    "\n",
    "\n",
    "We're going to focus on the `ChatCompletion` end point. \n",
    "\n",
    "```python\n",
    "class Prompter:\n",
    "    def __init__(self, api_key, gpt_model, temperature=0.2):\n",
    "        if not api_key:\n",
    "            raise Exception(\"Please provide the OpenAI API key\")\n",
    "\n",
    "        self.api_key  = api_key\n",
    "        self.gpt_model = gpt_model\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def prompt_model_return(self, messages: list):\n",
    "        openai.api_key = self.api_key\n",
    "        response = openai.ChatCompletion.create(model=self.gpt_model, \n",
    "                                                messages=messages,\n",
    "                                                temperature=self.temperature)\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950ed4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Roles in prompting the ChatCompletion endpoint</h1>\n",
    "\n",
    "`system content`: What context should the LLM have in mind? Expert in marketing, helpful assistant, enthusiastic marketing generator.\n",
    "\n",
    "`user content`: What are typical requests that someone with that role would receive?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f916e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Roles in prompting the ChatCompletion endpoint</h1>\n",
    "\n",
    "\n",
    "We're going to focus on the `ChatCompletion` end point. \n",
    "\n",
    "```python\n",
    "    def natural_language_to_sql(self, db_name:str, schema:str, natural_question:str):\n",
    "\n",
    "            system_content = f\"You are a data analyst, \\\n",
    "                               and you specialize in solving business questions with SQL.\\\n",
    "                               You are given a natural language question, \\\n",
    "                               and your role is to translate the question\\\n",
    "                               into a query that can be executed against a database. \\\n",
    "                               Ensure your queries are written in a single line, with no special characters\"\n",
    "            \n",
    "            user_content = f\"Please generate a SQL query for data with in a database named {db_name}\\\n",
    "                            along with a schema {schema} for the question {natural_question}\"\n",
    "\n",
    "            full_prompts = [\n",
    "                                    {\"role\" : \"system\", \"content\" : system_content},\n",
    "                                    {\"role\" : \"user\", \"content\" : user_content},\n",
    "                                    ]\n",
    "\n",
    "            result = self.prompt_model_return(full_prompts)\n",
    "\n",
    "            return result\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c35d2a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pm  = Prompter(open_ai_key, \"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "512cadce",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To determine the number of unique jobs in the table, we need to look at the 'job' column. We can use the DISTINCT keyword in SQL to get the unique values in that column. Here's an example SQL query to find the number of unique jobs:\\n\\nSELECT COUNT(DISTINCT job) AS unique_jobs\\nFROM bank;\\n\\nThis query will return the count of unique jobs in the 'job' column of the 'bank' table.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.natural_language_zero_shot(\"bank\", column_names, \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d926685",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(DISTINCT job) FROM bank'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.natural_language_single_shot(\"bank\", column_names, \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07651eaa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To find the number of unique jobs in the bank table, you can use the following SQL query:\\n\\nSELECT COUNT(DISTINCT job) FROM bank\\n\\nThis query will return the count of distinct job values in the \"job\" column of the bank table.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.natural_language_few_shot(\"bank\", column_names, \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c6569f9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(DISTINCT job) FROM bank'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.natural_language_with_roles(\"bank\", column_names, \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5666a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting open source LLMs through HuggingFace</h1>\n",
    "\n",
    "\n",
    "You need to ensure you install the right modules via `pip` along with the model card of the LLM.\n",
    "\n",
    "```\n",
    "<user_name>/<model_name>\n",
    "```\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/tap.png\" width=\"800px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "\n",
    "Source: https://huggingface.co/microsoft/tapex-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298d4ce7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting open source LLMs through HuggingFace</h1>\n",
    "\n",
    "Accessing models via HuggingFace can get complicated really quickly - there is no regulation for how the LLM should be presented, and different groups will have different approaches when packaging, encoding and decoding inputs/outputs (Pytorch, TensorFlow). \n",
    "\n",
    "Open LLMs also don't necessarily have the structure that OpenAI API has (roles for example). \n",
    "\n",
    "In the next section we will cover Python frameworks you can use to choose specialized open LLMs and build NLP applications with prompting and agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4941da",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Intermission: Q & A about prompting</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3670f6ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Introducing Haystack</h1>\n",
    "\n",
    "- Call open source models\n",
    "- Build NLP pipelines with their custom built tools\n",
    "- Leverage their prompt templates\n",
    "- Incorporate Agents\n",
    "- Deploy via REST API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac159149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python-LLM",
   "language": "python",
   "name": "llm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
