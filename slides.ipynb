{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94275820",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "import transformers\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import banking  # noqa: E402\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "open_ai_key = os.environ.get(\"openai-key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6932047b",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "_ = banking.BankingData(\"https://tinyurl.com/jb-bank\", \"bank\")\n",
    "_.extract_to_csv()\n",
    "\n",
    "# Loading in SQL extension\n",
    "%reload_ext sql\n",
    "# Initiating a DuckDB database named 'bank.duck.db' to run our SQL queries on\n",
    "%sql duckdb:///bank.duck.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90995634",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>4521</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "|  4521 |\n",
       "+-------+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "CREATE OR REPLACE TABLE bank AS\n",
    "FROM read_csv_auto('bank_cleaned.csv', header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a3c2a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = %sql PRAGMA table_info('bank');\n",
    "\n",
    "# Extract column names\n",
    "column_names = [row[1] for row in columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c18c8a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompts & Agents</h1>\n",
    "\n",
    "<h2 align='center'>How to incorporate prompting into your Python scripts <br>and expand their functionality through agents</h2>\n",
    "\n",
    "<h2 align='center'>Laura Funderburk</h2>\n",
    "\n",
    "<h2 align='center'>PyData Vancouver</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80b748",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Talk at a glance</h1>\n",
    "\n",
    "<h2 align='center'>Part I: Prompting (25 minutes)</h2>\n",
    "\n",
    "\n",
    "1. LLMs use cases and tasks\n",
    "2. The Generative AI project lifecycle \n",
    "3. Choosing the right LLM for the desired task\n",
    "4. Key elements of prompting & Prompting techniques\n",
    "5. Prompting private LLMs (OpenAI API): `ChatCompletion`\n",
    "6. Prompting open source LLMs through HuggingFace\n",
    "\n",
    "\n",
    "Q&A about prompting (5 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6bc99d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Talk at a glance</h1>\n",
    "\n",
    "<h2 align='center'>Part II: Incorporating agents (25 minutes)</h2>\n",
    "\n",
    "\n",
    "1. (Some) Applications of agents\n",
    "2. Introduction to Haystack\n",
    "3. Introduction to LangChain\n",
    "4. Which one to pick\n",
    "5. Techniques to combine prompting and agents\n",
    "\n",
    "Q&A about agents (5 minutes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af1efe1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>LLMs use cases and tasks</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1f923",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>LLMs use cases and tasks</h1>\n",
    "\n",
    "\n",
    "* Text summarization\n",
    "\n",
    "* Conversation \n",
    "\n",
    "* Translation\n",
    "\n",
    "* Text generation\n",
    "\n",
    "* Text, token and sentiment classification\n",
    "\n",
    "* Table Q&A and Q&A from unstructured data\n",
    "\n",
    "* Sentence similarity\n",
    "\n",
    "* Masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4370d0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>LLMs use cases and tasks</h1>\n",
    "\n",
    "<h2 align='center'>Your goal is to understand the business case you are solving -<br> then select the appropriate methods to solve it</h2>\n",
    "\n",
    "<h3 align='center'>Who will benefit from your product?</h3>\n",
    "\n",
    "<h3 align='center'>What is the end result?</h3>\n",
    "\n",
    "<h3 align='center'>How will it be served?</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8f6595",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>The generative AI project lifecycle</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f2a51",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>The generative AI project lifecycle</h1>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<center>\n",
    "  <img src=\"diagrams/genai_project_lifecycle.jpg\" width=\"1400px\"/>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ecc728",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Focus of this talk</h1>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/genai_project_lifecycle_focus.jpg\" width=\"1400px\"/>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68a8bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Choosing the right LLM (architecture) for the desired task</h1>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/opt.jpeg\" width=\"200px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "* GPT-like (also called auto-regressive Transformer models)\n",
    "* BERT-like (also called auto-encoding Transformer models)\n",
    "* BART/T5-like (also called sequence-to-sequence Transformer models)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0dfd13",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Choosing the right LLM (architecture) for the desired task</h1>\n",
    "\n",
    "* Encoder-only models: Good for tasks that require **understanding of the input** \n",
    "* Decoder-only models: Good for **generative tasks** \n",
    "* Encoder-decoder models or sequence-to-sequence models: Good for **generative tasks that require an input** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939aeee",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Do I need to train a new model to solve my problem?</h1>\n",
    "\n",
    "<h3 align='center'>No. Training a LLM is costly (GPU usage, time, resources, data). This is why sharing LLMs and their fine-tuned componets has become highly popularized.</h3>\n",
    "\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/hftasks.png\" width=\"1300px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "Source: https://huggingface.co/tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c31ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Key elements of prompting</h1>\n",
    "\n",
    "<h3 align='center'>Basic</h3>\n",
    "\n",
    "* A LLM to interact with\n",
    "* Temperature\n",
    "* Max tokens\n",
    "* A natural language request\n",
    "\n",
    "<h3 align='center'>Advanced</h3>\n",
    "\n",
    "* Data (text files, web files)\n",
    "* A database storage system (vector DB, SQL, PostgreSQL, etc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c2b5e7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting techniques</h1>\n",
    "\n",
    "* Zero-shot inference\n",
    "\n",
    "* One-shot inference\n",
    "\n",
    "* Few-shot inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175457fa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting techniques: Zero-shot inference</h1>\n",
    "\n",
    "Formula: prompt, no examples.\n",
    "\n",
    "Suppose we want to translate natural language queries into SQL. \n",
    "\n",
    "We have a `natural_question`, a database table name `db_name` and a schema `schema`\n",
    "\n",
    "```python\n",
    "prompt= f\"Answer the question {natural_question} for table {db_name} with schema {schema}\"        \n",
    "```\n",
    "\n",
    "Suppose we want to classify the sentiment in a sentence `sentence`\n",
    "\n",
    "```python\n",
    "prompt = f\"How does the author feel about this based on the statement {sentence}\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5554f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting techniques: One-shot inference</h1>\n",
    "\n",
    "Formula: prompt, one example.\n",
    "\n",
    "```python\n",
    "prompt= f\"Answer the question {natural_question} for table {db_name} with schema {schema}\\\n",
    "                        For example, if you receive the question: 'How many records are there?'\\\n",
    "                        An appropriate answer is\\\n",
    "                        'SELECT COUNT(*) FROM bank'\"\n",
    "```\n",
    "\n",
    "```python\n",
    "prompt = f\"How does the author feel about this based on the statement {sentence}\\\n",
    "            'I find the user experience is confusing and convoluted'\\\n",
    "            Answer: Negative\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db916187",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting techniques: Few-shot inference</h1>\n",
    "\n",
    "More than one example.\n",
    "\n",
    "```python\n",
    "prompt= f\"Answer the question {natural_question} for table {db_name} with schema {schema}\\\n",
    "                        For example, if you receive the question: 'How many records are there?'\\\n",
    "                        An appropriate answer is\\\n",
    "                        'SELECT COUNT(*) FROM bank'\"\n",
    "```\n",
    "\n",
    "```python\n",
    "prompt = f\"How does the author feel about this based on the statement {sentence}\\\n",
    "            'I find the user experience is confusing and convoluted'\\\n",
    "            Answer: Negative\\\n",
    "            'The decoration of the room made me feel welcome!'\\\n",
    "            Answer: Positive\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c64015",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting private LLMs (OpenAI API)</h1>\n",
    "\n",
    "\n",
    "We're going to focus on the `ChatCompletion` end point. \n",
    "\n",
    "Key elements:\n",
    "\n",
    "* OpenAI API Key\n",
    "* Model chosen (GPT4, GPT 3.5 Turbo, Text-Davinci)\n",
    "* Temperature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b78bf3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting private LLMs (OpenAI API)</h1>\n",
    "\n",
    "\n",
    "We're going to focus on the `ChatCompletion` end point. \n",
    "\n",
    "```python\n",
    "class Prompter:\n",
    "    def __init__(self, api_key, gpt_model, temperature=0.2):\n",
    "        if not api_key:\n",
    "            raise Exception(\"Please provide the OpenAI API key\")\n",
    "\n",
    "        self.api_key  = api_key\n",
    "        self.gpt_model = gpt_model\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def prompt_model_return(self, messages: list):\n",
    "        openai.api_key = self.api_key\n",
    "        response = openai.ChatCompletion.create(model=self.gpt_model, \n",
    "                                                messages=messages,\n",
    "                                                temperature=self.temperature)\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950ed4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Roles in prompting the ChatCompletion endpoint</h1>\n",
    "\n",
    "`system content`: What context should the LLM have in mind? Expert in marketing, helpful assistant, enthusiastic marketing generator.\n",
    "\n",
    "`user content`: What are typical requests that someone with that role would receive?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f916e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h1 align='center'>Roles in prompting the ChatCompletion endpoint</h1>\n",
    "\n",
    "\n",
    "We're going to focus on the `ChatCompletion` end point. \n",
    "\n",
    "```python\n",
    "    def natural_language_to_sql(self, db_name:str, schema:str, natural_question:str):\n",
    "\n",
    "            system_content = f\"You are a data analyst, \\\n",
    "                               and you specialize in solving business questions with SQL.\\\n",
    "                               You are given a natural language question, \\\n",
    "                               and your role is to translate the question\\\n",
    "                               into a query that can be executed against a database. \\\n",
    "                               Ensure your queries are written in a single line, with no special characters\"\n",
    "            \n",
    "            user_content = f\"Please generate a SQL query for data with in a database named {db_name}\\\n",
    "                            along with a schema {schema} for the question {natural_question}\"\n",
    "\n",
    "            full_prompts = [\n",
    "                                    {\"role\" : \"system\", \"content\" : system_content},\n",
    "                                    {\"role\" : \"user\", \"content\" : user_content},\n",
    "                                    ]\n",
    "\n",
    "            result = self.prompt_model_return(full_prompts)\n",
    "\n",
    "            return result\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e891a2e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class Prompter:\n",
    "    def __init__(self, api_key, gpt_model, temperature=0.2):\n",
    "        if not api_key:\n",
    "            raise Exception(\"Please provide the OpenAI API key\")\n",
    "\n",
    "        self.api_key  = api_key\n",
    "        self.gpt_model = gpt_model\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    def chat_completion(self, messages: list):\n",
    "        openai.api_key = self.api_key\n",
    "        response = openai.ChatCompletion.create(model=self.gpt_model, \n",
    "                                                messages=messages,\n",
    "                                                temperature=self.temperature)\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    def natural_language_to_sql(self, db_name:str, schema:str, natural_question:str):\n",
    "\n",
    "        system_content = f\"You are a data analyst, and you specialize in solving business questions with SQL.\\\n",
    "                        You are given a natural language question, and your role is to translate the question\\\n",
    "                        into a query that can be executed against a database. \\\n",
    "                        Ensure your queries are written in a single line, with no special characters\"\n",
    "        user_content = f\"Please generate a SQL query for data with in a database named {db_name}\\\n",
    "                        along with a schema {schema} for the question {natural_question}\"\n",
    "\n",
    "        full_prompts = [\n",
    "                                {\"role\" : \"system\", \"content\" : system_content},\n",
    "                                {\"role\" : \"user\", \"content\" : user_content},\n",
    "                                ]\n",
    "        \n",
    "        result = self.chat_completion(full_prompts)\n",
    "\n",
    "        return result\n",
    "   \n",
    "    \n",
    "    def natural_language_zero_shot(self, db_name:str, schema:str, natural_question:str):\n",
    "        user_content= f\"Answer the question {natural_question} for table {db_name} with schema {schema}\"\n",
    "        \n",
    "        full_prompt = [{\"role\" : \"user\", \"content\" : user_content}]\n",
    "        \n",
    "        \n",
    "        result = self.chat_completion(full_prompt)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def natural_language_single_shot(self, db_name:str, schema:str, natural_question:str):\n",
    "        user_content= f\"Answer the question {natural_question} for table {db_name} with schema {schema}\\\n",
    "                        For example, if you receive the question: 'How many records are there?'\\\n",
    "                        An appropriate answer is\\\n",
    "                        'SELECT COUNT(*) FROM bank'\"\n",
    "        \n",
    "        full_prompt = [{\"role\" : \"user\", \"content\" : user_content}]\n",
    "        \n",
    "        \n",
    "        result = self.chat_completion(full_prompt)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def natural_language_few_shot(self, db_name:str, schema:str, natural_question:str):\n",
    "        user_content= f\"Answer the question {natural_question} for table {db_name} with schema {schema}\\\n",
    "                        For example, if you receive the question: 'How many records are there?'\\\n",
    "                        'SELECT COUNT(*) FROM bank'\\\n",
    "                        If you receive the question: Find all employees that are unemployed\\\n",
    "                        SELECT * FROM bank WHERE job = 'unemployed'\"\n",
    "        \n",
    "        full_prompt = [{\"role\" : \"user\", \"content\" : user_content}]\n",
    "        \n",
    "        \n",
    "        result = self.chat_completion(full_prompt)\n",
    "\n",
    "        return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d4afe1c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(DISTINCT job) FROM bank'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm  = Prompter(open_ai_key, \"gpt-3.5-turbo\")\n",
    "\n",
    "pm.natural_language_to_sql(\"bank\", column_names, \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ec630",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.natural_language_zero_shot(\"bank\", column_names, \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c574257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.natural_language_single_shot(\"bank\", column_names, \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5666a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting open source LLMs through HuggingFace</h1>\n",
    "\n",
    "\n",
    "You only need to ensure you install the right modules via `pip` along with the model card of the LLM.\n",
    "\n",
    "```\n",
    "<user_name>/<model_name>\n",
    "```\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/tap.png\" width=\"800px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "Source: https://huggingface.co/microsoft/tapex-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd1f5f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting open source LLMs through HuggingFace</h1>\n",
    "\n",
    "\n",
    "You only need to ensure you install the right modules via `pip` along with the model card of the LLM.\n",
    "\n",
    "```\n",
    "<user_name>/<model_name>\n",
    "```\n",
    "\n",
    "When you execute the download code you should see something like\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/model_download.png\" width=\"800px\"/>\n",
    "\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27347cf1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TapexTokenizer, BartForConditionalGeneration\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class OpenSourcePrompter:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "        \n",
    "    def call_model(self, full_prompt):\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(self.model_name)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.model_name, use_fast=True)\n",
    "        \n",
    "        inputs = tokenizer(full_prompt, return_tensors='pt')\n",
    "        output = tokenizer.decode(\n",
    "            model.generate(\n",
    "                inputs[\"input_ids\"], \n",
    "                max_new_tokens=50,\n",
    "            )[0], \n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def natural_language_to_sql(self, db_name:str, schema:list, natural_question:str):\n",
    "\n",
    "        prompt = f\"Given the natural language question {natural_question}\\\n",
    "                        the database table {db_name}, \\\n",
    "                        and the table schema {', '.join(schema)}\\\n",
    "                        generate a SQL query that answers the question {natural_question}\"\n",
    "\n",
    "    \n",
    "        result = self.call_model(prompt)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589de24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TapexTokenizer, BartForConditionalGeneration\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class TapexTokenizer:\n",
    "    def __init__(self, table):\n",
    "        self.table = table\n",
    "        \n",
    "    def tapex_tokenizer(self, query):\n",
    "        \n",
    "        tokenizer = TapexTokenizer.from_pretrained(\"microsoft/tapex-base\")\n",
    "        model = BartForConditionalGeneration.from_pretrained(\"microsoft/tapex-base\")\n",
    "            \n",
    "        # tapex accepts uncased input since it is pre-trained on the uncased corpus\n",
    "        query = \"select year where city = beijing\"\n",
    "        encoding = tokenizer(table=self.table, query=query, return_tensors=\"pt\")\n",
    "\n",
    "        outputs = model.generate(**encoding)\n",
    "\n",
    "        return tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6507b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_name='google/flan-t5-base'\n",
    "opm = OpenSourcePrompter(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0951c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opm.natural_language_to_sql(\"bank\", column_names, \"How many records are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c0e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sqlcmd explore --table bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4118c5c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset = load_dataset(huggingface_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='google/flan-t5-base'\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f03e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import PromptNode\n",
    "\n",
    "# Initalize the node passing the model:\n",
    "prompt_node = PromptNode(model_name_or_path=\"google/flan-t5-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6b7b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go ahead and ask a question:\n",
    "prompt_node(\"What is the best city in Europe to live in?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082358c",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"system\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863b49a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn = PromptNode(\"gpt-4\", api_key=open_ai_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What is the best city in Europe to live in?\"\n",
    "pn(prompt, max_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b5ce81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python-LLM",
   "language": "python",
   "name": "llm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
