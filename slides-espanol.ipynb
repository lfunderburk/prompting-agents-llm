{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94275820",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "import transformers\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "import banking  # noqa: E402\n",
    "from private_prompting import Prompter\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "open_ai_key = os.environ.get(\"openai-key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b54edc",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Download data and initialize a DuckDB instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a3cb54",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "_ = banking.BankingData(\"https://tinyurl.com/jb-bank\", \"bank\")\n",
    "_.extract_to_csv()\n",
    "\n",
    "# Loading in SQL extension\n",
    "%reload_ext sql\n",
    "# Initiating a DuckDB database named 'bank.duck.db' to run our SQL queries on\n",
    "%sql duckdb:///banco.duck.db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b58650",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Create table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cec2da1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///banco.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///banco.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>4521</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "|  4521 |\n",
       "+-------+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql CREATE OR REPLACE TABLE bank AS FROM read_csv_auto('bank_cleaned.csv', header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edb07c67",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///banco.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///banco.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract column names\n",
    "columns = %sql PRAGMA table_info('bank');\n",
    "column_names = [row[1] for row in columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c18c8a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompts (indicaciones)  & Agentes</h1>\n",
    "\n",
    "<h3 align='center'>Cómo incorporar Prompts en tus scripts de Python y expandir su funcionalidad a través de los agentes</h3>\n",
    "\n",
    "<h4 align='center'>Laura Funderburk</h4>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b666908",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Sobre mí</h2>\n",
    "\n",
    "* Developer Advocate @ Ploomber (hablando y compartiendo conocimientos sobre herramientas para mejorar el flujo de trabajo de la ciencia de datos)\n",
    "\n",
    "* Anteriormente científica de datos (sector con fines de lucro, sector sin fines de lucro)\n",
    "\n",
    "* Profundamente curiosa acerca de la IA generativa, Modelos de Lenguaje Grande, con un enfoque en ingeniería y automatización\n",
    "\n",
    "* Utilizo LLMs, indicaciones y agentes para automatizar tareas de trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be80b748",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Resumen de la charla</h2>\n",
    "\n",
    "<h3 align='center'>Parte I: Indicaciones (40 minutos)</h3>\n",
    "\n",
    "1. Casos de uso y tareas de LLMs\n",
    "2. El ciclo de vida del proyecto de IA Generativa\n",
    "3. Elegir la arquitectura de LLM correcta\n",
    "4. Elementos clave de las indicaciones y técnicas de indicación\n",
    "5. Indicaciones para LLMs privados (API de OpenAI): ChatCompletion\n",
    "6. Indicaciones para LLMs de código abierto a través de HuggingFace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6bc99d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Resumen de la charla</h2>\n",
    "\n",
    "<h3 align='center'>Parte II: Agentes y marcos de trabajo de código abierto (20 minutos)</h3>\n",
    "\n",
    "1. ¿Qué son los agentes?\n",
    "2. Introducción a Haystack\n",
    "3. Introducción a LangChain\n",
    "4. Técnicas para combinar indicaciones y agentes para el despliegue de aplicaciones\n",
    "5. Pros y contras de cada uno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb9f5f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Parte I: Indicaciones</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb1f923",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Casos de uso y tareas de LLMs</h2>\n",
    "\n",
    "* Resumen de texto\n",
    "\n",
    "* Conversación\n",
    "\n",
    "* Traducción\n",
    "\n",
    "* Generación de texto\n",
    "\n",
    "* Clasificación de texto, tokens y sentimientos\n",
    "\n",
    "* Preguntas y respuestas de tablas y de datos no estructurados\n",
    "\n",
    "* Similitud de frases\n",
    "\n",
    "* Enmascaramiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4370d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Casos de uso y tareas de LLMs</h2>\n",
    "\n",
    "<h3 align='center'>Tu objetivo es entender el caso de negocio que estás resolviendo, y luego seleccionar los métodos apropiados para resolverlo</h3>\n",
    "\n",
    "$\\Rightarrow$ ¿Quién se beneficiará de tu producto?\n",
    "\n",
    "$\\Rightarrow$ ¿Cuáles son las restricciones empresariales (tiempo, datos, recursos)?\n",
    "\n",
    "$\\Rightarrow$ ¿Cuál es el resultado final?\n",
    "\n",
    "$\\Rightarrow$ ¿Cómo será servido?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3f2a51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>El ciclo de vida del proyecto de IA generativa</h2>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "<center>\n",
    "  <img src=\"diagrams/genai_project_lifecycle.jpg\" width=\"1200px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "Source: Coursera, Generative AI with LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ecc728",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Enfoque de esta charla</h2>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/genai_project_lifecycle_focus.jpg\" width=\"1200px\"/>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68a8bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Elegir la arquitectura de LLM correcta</h2>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/opt.jpeg\" width=\"200px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "* Transformadores solo de decodificador: Bueno para **tareas generativas** (auto-regresivas)\n",
    "* Transformadores solo de codificador: Bueno para tareas que requieren **entender la entrada de datos** (auto-codificación)\n",
    "* Transformadores de codificador-decodificador o modelos de secuencia a secuencia: Bueno para **tareas generativas que requieren entrada de datos**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0dfd13",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Elegir la arquitectura de LLM correcta </h2>\n",
    "\n",
    "<p></p>\n",
    "\n",
    "|Tipo de Transformador\t| Arquitectura\t| Modelo similar\t| Enfoque\t|Ejemplo|\n",
    "|-|-|-|-|-|\n",
    "| Auto-regresivo\t| Solo decodificador\t| Tipo GPT\t| Tareas generativas\t|Chat bot |\n",
    "| Auto-codificación\t| Solo codificador\t| Tipo BERT\t| Comprensión de la entrada\tde datos| Respuesta a preguntas|\n",
    "| Secuencia-a-Secuencia\t| Codificador-decodificador|\tTipo BART/T5\t| Tareas generativas que requieren una entrada\t| Traducción de idiomas|\n",
    "\n",
    "\n",
    "<p></p>\n",
    "\n",
    "[https://github.com/christianversloot/machine-learning-articles](https://github.com/christianversloot/machine-learning-articles/blob/main/differences-between-autoregressive-autoencoding-and-sequence-to-sequence-models-in-machine-learning.md)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939aeee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>¿Necesito entrenar un nuevo modelo para resolver mi problema?</h2>\n",
    "\n",
    "**No. Entrenar un LLM es costoso (uso de GPU, tiempo, cálculo, datos). Por eso, compartir LLMs y sus componentes afinados se ha vuelto muy popular.**\n",
    "\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/hftasks.png\" width=\"1200px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "Puedes comenzar indicando a un LLM, luego afinando* si no estás obteniendo los resultados que deseas. Necesitarás curar un conjunto de datos para esto.\n",
    "\n",
    "*(ajuste de instrucciones o, por ejemplo, PEFT + LoRA) Parameter Efficient Fine Tuning\n",
    "\n",
    "Fuente: https://huggingface.co/tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57ef893",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Prompting (Indicaciones)</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c31ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Elementos clave de las indicaciones</h2>\n",
    "\n",
    "<h3 align='center'>Básico</h3>\n",
    "\n",
    "* Un LLM con el que interactuar\n",
    "* Temperatura\n",
    "* Tokens máximos\n",
    "* Una solicitud en lenguaje natural\n",
    "\n",
    "<h3 align='center'>Avanzado</h3>\n",
    "\n",
    "* Datos (archivos de texto, archivos web)\n",
    "* Un sistema de almacenamiento de base de datos (DB vectorial, SQL, PostgreSQL, etc)\n",
    "* Interfaces de usuario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c2b5e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Técnicas de indicación</h2>\n",
    "\n",
    "* Inferencia de cero disparos\n",
    "\n",
    "* Inferencia de un solo disparo\n",
    "\n",
    "* Inferencia de pocos disparos\n",
    "\n",
    "* Cadena de pensamiento\n",
    "\n",
    "* Roles (API de OpenAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c64015",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Indicaciones para LLMs privados (API de OpenAI)</h2>\n",
    "\n",
    "Vamos a centrarnos en la funcionalidad `ChatCompletion`.\n",
    "\n",
    "Elementos clave:\n",
    "\n",
    "* Clave de API de OpenAI\n",
    "* Modelo elegido (GPT4, GPT 3.5 Turbo, Text-Davinci)\n",
    "* Temperatura\n",
    "* Tu indicación\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175457fa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Técnicas de indicación: Inferencia de cero disparos</h3>\n",
    "\n",
    "**Fórmula: instrucción, sin ejemplos.**\n",
    "\n",
    "Supongamos que queremos traducir una pregunta en lenguaje natural a SQL.\n",
    "\n",
    "```python\n",
    "prompt = f\"Responde a la pregunta {natural_question} \\\n",
    "           para la tabla {db_name} \\\n",
    "           con esquema {schema}\"\n",
    "```\n",
    "\n",
    "```\n",
    "SELECT * FROM table\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5554f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Técnicas de indicación: Inferencia de un solo disparo</h3>\n",
    "\n",
    "**Fórmula: instrucción, un ejemplo.**\n",
    "\n",
    "```python\n",
    "prompt = f\"Responde a la pregunta {natural_question} \\\n",
    "           para la tabla {db_name} \\\n",
    "           con esquema {schema}\\\n",
    "               Pregunta: ¿Cuántos registros hay?\\\n",
    "               Respuesta: SELECT COUNT(*) FROM bank\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db916187",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Técnicas de indicación: Inferencia de pocos disparos</h3>\n",
    "\n",
    "**Fórmula: instrucción, más de un ejemplo.**\n",
    "\n",
    "```python\n",
    "prompt = f\"Responde a la pregunta {natural_question} \\\n",
    "           para la tabla {db_name} \\\n",
    "           con esquema {schema}\\\n",
    "           Pregunta: ¿Cuántos registros hay?\\\n",
    "           Respuesta: SELECT COUNT(*) FROM bank\\\n",
    "           Pregunta: Encuentra todos los empleados que están desempleados\\\n",
    "           Respuesta: SELECT * FROM bank WHERE job = 'unemployed'\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6950ed4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Roles en la indicación del punto final de ChatCompletion (solo API de OpenAI)</h3>\n",
    "\n",
    "El 'rol' puede tomar uno de tres valores: system, user o el assistant\n",
    "\n",
    "`content` contiene el texto del mensaje del role.\n",
    "\n",
    "`system` Puedes usar una instrucción a nivel de sistema para guiar el comportamiento de tu modelo a lo largo de la conversación.\n",
    "\n",
    "`user` ¿Cuáles son las solicitudes típicas que alguien en ese rol recibiría?\n",
    "\n",
    "`assistant` Este rol representa al modelo de lenguaje, como ChatGPT, que genera respuestas basadas en los mensajes proporcionados por el usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b0aca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Problema empresarial: traducir preguntas en lenguaje natural a SQL</h2>\n",
    "\n",
    "Podemos resolver este problema con indicaciones y el punto final ChatCompletion en la API de OpenAI.\n",
    "\n",
    "**Enfoque: construir una clase Prompter y añadir cada técnica de indicación como un método, luego evaluar los resultados**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b78bf3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Enfoque: inicializar una clase Prompter</h3>\n",
    "\n",
    "```python\n",
    "import openai\n",
    "\n",
    "class Prompter:\n",
    "    def __init__(self, api_key, gpt_model, temperature=0.2):\n",
    "        if not api_key:\n",
    "            raise Exception(\"Please provide the OpenAI API key\")\n",
    "\n",
    "        self.api_key  = api_key\n",
    "        self.gpt_model = gpt_model\n",
    "        self.temperature = temperature\n",
    "    \n",
    "    \n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda4f5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Enfoque: añadir un método de completado de chat para llamar a un modelo tipo GPT (API de OpenAI)</h3>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/init-chatcompletion.png\" width=\"2000px\"/>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cef98f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Enfoque: añadir un método con una indicación de un solo disparo y el rol de asistente</h3>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/prompt-roles-assistant.png\" width=\"2000px\"/>\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f916e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Enfoque: añadir un método con una indicación de un solo disparo y el rol de asistente</h3>\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/prompt-roles-sql.png\" width=\"1600px\"/>\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde69af5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Evaluar resultados</h2>\n",
    "\n",
    "Supongamos que tengo una instancia en memoria de DuckDB con una tabla llamada bank que se ve así."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa3d5a3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%sqlcmd explore --table bank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197e3d9f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Evaluar resultados</h2>\n",
    "\n",
    "Probemos las diferentes técnicas de indicación.\n",
    "\n",
    "Le pediremos al modelo GPT-3.5-turbo de la API de OpenAI que traduzca una pregunta en lenguaje natural a SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4cc297",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm  = Prompter(open_ai_key, \"gpt-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420334b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Zero-shot results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2e073",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_zero_shot(\"bank\", \n",
    "                              column_names, \n",
    "                              \"How many unique jobs are there?\") # SELECT DISTINCT JOB FROM BANK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988f4107",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_zero_shot(\"bank\", \n",
    "                              column_names, \n",
    "                              \"What is the total balance for \\\n",
    "                               employees by education?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84781b46",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Resultados de un solo disparo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018d103",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_single_shot(\"bank\", \n",
    "                                column_names, \n",
    "                                \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c7c68",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_single_shot(\"bank\", \n",
    "                                column_names, \n",
    "                                \"What is the total balance for \\\n",
    "                                employees by education?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742bab4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Resultados basados en roles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079af235",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_with_roles(\"bank\", \n",
    "                               column_names, \n",
    "                               \"How many unique jobs are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa8821c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pm.natural_language_with_roles(\"bank\", \n",
    "                               column_names, \n",
    "                               \"What is the total balance for\\\n",
    "                               employees by education?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2aace6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT education, SUM(balance) AS total_balance\n",
    "FROM bank\n",
    "GROUP BY education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab5666a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Prompting/Indicaciones para LLMs de código abierto a través de HuggingFace</h3>\n",
    "\n",
    "Necesitas asegurarte de instalar los módulos correctos a través de pip junto con cualquier módulo especificado en la tarjeta del modelo del LLM.\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/hftasks.png\" width=\"800px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "\n",
    "Ejemplo: https://huggingface.co/microsoft/tapex-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3868107",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>La realidad de prompting en modelos de código abierto</h3>\n",
    "\n",
    "\n",
    "<p></p>\n",
    "<center>\n",
    "  <img src=\"diagrams/this-is-fine.jpeg\" width=\"600px\"/>\n",
    "\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65aa906",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>La realidad de las indicaciones en modelos de código abierto</h3>\n",
    "\n",
    "* Los modelos alojados en HuggingFace se asemejan a repositorios de GitHub (pero no de una buena manera).\n",
    "* Necesitarás sentirte cómodo usando las bibliotecas transformers, PyTorch y TensorFlow.\n",
    "* Necesitarás algo más que solo comodidad con las arquitecturas de transformadores.\n",
    "* Infierno de dependencias.\n",
    "* Los resultados de las indicaciones varían entre diferentes modelos.\n",
    "* La documentación del modelo varía desde inexistente hasta altamente técnica (artículos de investigación).\n",
    "* Mayor probabilidad de que necesites encontrar el modelo base y afinarlo con tus datos para obtener mejores resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0339ba2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Indicando a un modelo tipo T5 para traducir NL a SQL</h3>\n",
    "\n",
    "Exploraremos la funcionalidad del modelo afinado tipo T5 `mrm8488/t5-base-finetuned-wikiSQL.`\n",
    "\n",
    "Recuerda que los modelos tipo T5 son de tipo codificador-decodificador y son buenos para traducir entre idiomas.\n",
    "\n",
    "Este modelo fue afinado en el conjunto de datos wiki-SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0a676",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "```python\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8bedc4",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")\n",
    "model = AutoModelWithLMHead.from_pretrained(\"mrm8488/t5-base-finetuned-wikiSQL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84aeff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_sql(query):\n",
    "    input_text = \"translate English to SQL: %s </s>\" % query\n",
    "    features = tokenizer([input_text], \n",
    "                         return_tensors='pt')\n",
    "\n",
    "    output = model.generate(input_ids=features['input_ids'], \n",
    "                           attention_mask=features['attention_mask'],\n",
    "                            max_new_tokens=200)\n",
    "\n",
    "    return tokenizer.decode(output[0])\n",
    "\n",
    "# Translate\n",
    "natural_question = \"How many entries are there?\" \n",
    "db_name = \"banks\"\n",
    "schema = column_names\n",
    "\n",
    "prompt = f\"{natural_question} \\\n",
    "           for table {db_name} \\\n",
    "           with schema {schema}\"\n",
    "\n",
    "get_sql(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de1ce9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Cómo guiar tus elecciones</h3>\n",
    "\n",
    "1. Recuerda tu caso de uso, las restricciones empresariales y quién usará tu aplicación\n",
    "2. Recuerda los tres modelos base y sus palabras clave\n",
    "3. Prepárate para la posibilidad de afinar\n",
    "\n",
    "<p> </p>\n",
    "\n",
    "|Tipo de Transformador\t| Arquitectura\t| Modelo similar\t| Enfoque\t|Ejemplo|\n",
    "|-|-|-|-|-|\n",
    "| Auto-regresivo\t| Solo decodificador\t| Tipo GPT\t| Tareas generativas\t|Chat bot |\n",
    "| Auto-codificación\t| Solo codificador\t| Tipo BERT\t| Comprensión de la entrada\tde datos| Respuesta a preguntas|\n",
    "| Secuencia-a-Secuencia\t| Codificador-decodificador|\tTipo BART/T5\t| Tareas generativas que requieren una entrada\t| Traducción de idiomas|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121dcfb7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Parte II: Agentes y marcos de trabajo de código abierto</h1>\n",
    "\n",
    "Ahora dirigiremos nuestra atención a dos marcos de trabajo de código abierto que puedes utilizar para aumentar la funcionalidad de las indicaciones a través de agentes: LangChain y Haystack.\n",
    "\n",
    "\n",
    "Los marcos de trabajo presentados aquí pueden ser instalados vía pip e importados como módulos en tu script de Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15f27d8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<h2 align='center'>¿Qué son los agentes?</h2>\n",
    "\n",
    "El papel de un agente es empoderar a los LLMs para decidir qué acciones tomar, otorgándoles un cierto grado de autonomía. En términos simples, los agentes son una fusión de cadenas de LLMs (que son secuencias de LLMs) y herramientas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021b7b0b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Introduciendo LangChain</h2>\n",
    "\n",
    "<center>\n",
    "  <img src=\"diagrams/langchain.png\" width=\"300px\"/>\n",
    "</center>\n",
    "\n",
    "LangChain es un marco de trabajo para desarrollar aplicaciones impulsadas por modelos de lenguaje. Permite aplicaciones que son:\n",
    "\n",
    "* Conscientes de los datos: conecta un modelo de lenguaje con otras fuentes de datos\n",
    "\n",
    "* Agentes: permite a un modelo de lenguaje interactuar con su entorno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5624e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>¿Cómo aborda LangChain los Agentes?</h2>\n",
    "\n",
    "<p> </p>\n",
    "\n",
    "<center>\n",
    "  <img src=\"diagrams/langchain.jpg\" width=\"1200px\"/>\n",
    "\n",
    "</center>\n",
    "\n",
    "Con `LangChain` pensamos en términos de **componentes** y **cadenas listas para usar**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283a276a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Cómo incorporarlo en tus scripts</h2>\n",
    "\n",
    "Puedes construir tus funciones personalizadas en Python y utilizar su decorador @tool. Luego de inicializar LangChain junto con el modelo GPT que quieras, puedes pedirle que realice tareas con comandos de lenguaje natural.\n",
    "\n",
    "**Es hora de un mini-demo.**\n",
    "\n",
    "Herramientas que se le dieron al agente:\n",
    "\n",
    "1. Un rastreador web\n",
    "2. Un indicador basado en GPT con contenido de system y user\n",
    "3. Instrucciones para resumir la página web y luego escribir una publicación en redes sociales sobre el resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d9284a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Introduciendo Haystack</h2>\n",
    "\n",
    "<center>\n",
    "  <img src=\"diagrams/haystack-ogimage.png\" width=\"500px\"/>\n",
    "</center>\n",
    "\n",
    "Haystack es un marco de trabajo de código abierto para construir sistemas de búsqueda que funcionan de manera inteligente sobre grandes colecciones de documentos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa31768",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Funcionalidad:\n",
    "\n",
    "* Llama a modelos de código abierto, modelos alojados (Azure, AWS) así como privados (API de OpenAI)\n",
    "* Construye pipelines de NLP listos para producción con sus herramientas personalizadas\n",
    "* Maquinaria para el procesamiento de datos no estructurados (texto)\n",
    "* Aprovecha sus plantillas de indicaciones ([prompt-hub](https://prompthub.deepset.ai/))\n",
    "* Incorpora Agentes\n",
    "* Compatibilidad con Vector y DB clásica.\n",
    "* Lanza a produccion vía REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2916f9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>¿Cómo aborda Haystack los Agentes?</h2>\n",
    "\n",
    "**Nodos:** cada Nodo logra una cosa\n",
    "\n",
    "**Pipelines:** esta es la estructura estándar de Haystack que puede conectarse a tus datos y realizar en ellos tareas de NLP que tú defines.\n",
    "\n",
    "**Herramientas:** puedes pensar en una Herramienta como un experto, que es capaz de hacer algo realmente bien.\n",
    "\n",
    "**Agente:** un componente que está impulsado por un LLM, como GPT-3. Puede utilizar herramientas y decidir el próximo mejor curso de acción para llegar al resultado de una consulta."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5136c6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2 align='center'>Creando un nodo personalizado para realizar consultas SQL en Jupyter</h2>\n",
    "\n",
    "Vamos a utilizar ``JupySQL`` para realizar las consultas.\n",
    "\n",
    "``JupySQL`` se desarrolló sobre iPython-SQL y su propósito es conectarse a BDs de varios tipos y ejecutar queries en Jupyter.\n",
    "\n",
    "Esta será nuestra herramienta: ``JupySQLQuery`` y la definiremos como una subclase de la clase `BaseComponent` en Haystack.\n",
    "\n",
    "También crearemos una indicación con instrucciones detalladas sobre cómo debe responder el agente a diferentes situaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e97a2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "  <img src=\"diagrams/JupySQL-agent.png\" width=\"500px\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba05f565",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(duckdb.IOException) IO Error: Could not set lock on file \"/Users/macpro/Documents/GitHub/prompting-agents-llm/bank.duck.db\": Resource temporarily unavailable\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes.base import BaseComponent\n",
    "\n",
    "class JupySQLQuery(BaseComponent):\n",
    "    outgoing_edges = 1\n",
    "    \n",
    "    def __init__(self):\n",
    "        %reload_ext sql\n",
    "        %sql duckdb:///bank.duck.db\n",
    "\n",
    "    def run(self, query: str):\n",
    "        result = %sql {{query}}\n",
    "        output = {\n",
    "            \"results\":  f\"{result}\",\n",
    "            \"query\": query,\n",
    "            \n",
    "        }\n",
    "        return output\n",
    "\n",
    "    def run_batch(self, queries: list):\n",
    "        results = []\n",
    "        for query in queries:\n",
    "            result = %sql {query}\n",
    "            output = {\n",
    "                \"results\":  f\"{result}\",\n",
    "                \"query\": query,\n",
    "            }\n",
    "            results.append(output)\n",
    "        return results\n",
    "\n",
    "    \n",
    "jupy_sql_query = JupySQLQuery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29dca2a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from haystack.agents import Tool\n",
    "from haystack.nodes import PromptNode\n",
    "from jupysqlagent import sql_agent_prompt\n",
    "from haystack.agents import Agent, Tool\n",
    "\n",
    "jupy_sql_query_tool = Tool(name=\"JupySQL_Query\", \n",
    "                           pipeline_or_node=jupy_sql_query, \n",
    "                           description=\"\"\"This tool is useful for consuming SQL queries \\\n",
    "                                        and responds with the result\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee904a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Get the API key\n",
    "openai_api_key = os.environ.get(\"openai-key\")\n",
    "chosen_model = \"gpt-4\"\n",
    "\n",
    "\n",
    "# Define a prompt node that uses the GPT-4 model\n",
    "prompt_node = PromptNode(model_name_or_path=chosen_model, \n",
    "                         api_key=openai_api_key, \n",
    "                         stop_words=[\"Observation:\"], \n",
    "                         max_length=1000)\n",
    "\n",
    "# Define the agent\n",
    "agent = Agent(prompt_node=prompt_node, \n",
    "              prompt_template=sql_agent_prompt)\n",
    "\n",
    "agent.add_tool(jupy_sql_query_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d317049",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent custom-at-query-time started with {'query': 'How many records are there', 'params': None}\n",
      "\u001b[32mcount\u001b[0m\u001b[32m the\u001b[0m\u001b[32m number\u001b[0m\u001b[32m of\u001b[0m\u001b[32m records\u001b[0m\u001b[32m in\u001b[0m\u001b[32m the\u001b[0m\u001b[32m '\u001b[0m\u001b[32mbank\u001b[0m\u001b[32m'\u001b[0m\u001b[32m table\u001b[0m\u001b[32m.\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m J\u001b[0m\u001b[32mupy\u001b[0m\u001b[32mSQL\u001b[0m\u001b[32m_Query\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m select\u001b[0m\u001b[32m count\u001b[0m\u001b[32m(*)\u001b[0m\u001b[32m from\u001b[0m\u001b[32m bank\u001b[0m\u001b[32m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'execute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow many records are there\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/haystack/agents/base.py:359\u001b[0m, in \u001b[0;36mAgent.run\u001b[0;34m(self, query, max_steps, params)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m agent_step\u001b[38;5;241m.\u001b[39mis_last():\n\u001b[0;32m--> 359\u001b[0m         agent_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_agent_finish(agent_step)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/haystack/agents/base.py:373\u001b[0m, in \u001b[0;36mAgent._step\u001b[0;34m(self, query, current_step, params)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_agent_step(next_step)\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# run the tool selected by the LLM\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_node_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m next_step\u001b[38;5;241m.\u001b[39mis_last() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# save the input, output and observation to memory (if memory is enabled)\u001b[39;00m\n\u001b[1;32m    376\u001b[0m memory_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_data_for_memory(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mquery, output\u001b[38;5;241m=\u001b[39mprompt_node_response, observation\u001b[38;5;241m=\u001b[39mobservation)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/haystack/agents/base.py:178\u001b[0m, in \u001b[0;36mToolsManager.run_tool\u001b[0;34m(self, llm_response, params)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e, tool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools[tool_name])\n\u001b[0;32m--> 178\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tool_result\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/haystack/agents/base.py:167\u001b[0m, in \u001b[0;36mToolsManager.run_tool\u001b[0;34m(self, llm_response, params)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_tool_start(tool_input, tool\u001b[38;5;241m=\u001b[39mtool)\n\u001b[0;32m--> 167\u001b[0m     tool_result \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_tool_finish(\n\u001b[1;32m    169\u001b[0m         tool_result,\n\u001b[1;32m    170\u001b[0m         observation_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObservation: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m         tool_input\u001b[38;5;241m=\u001b[39mtool_input,\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/haystack/agents/base.py:92\u001b[0m, in \u001b[0;36mTool.run\u001b[0;34m(self, tool_input, params)\u001b[0m\n\u001b[1;32m     90\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_or_node(tool_input)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_or_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_result(result)\n",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m, in \u001b[0;36mJupySQLQuery.run\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msql\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m{{\u001b[39;49m\u001b[38;5;124;43mquery}}\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     output \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query,\n\u001b[1;32m     15\u001b[0m         \n\u001b[1;32m     16\u001b[0m     }\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2417\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2417\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2420\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2421\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/sql/magic.py:318\u001b[0m, in \u001b[0;36mSqlMagic.execute\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;129m@no_var_expand\u001b[39m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;129m@needs_local_scope\u001b[39m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;129m@line_magic\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msql\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m )\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, line\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, cell\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, local_ns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    Runs SQL statement against a database, specified by\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    SQLAlchemy connect string.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m \n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_ns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_interactive_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/ploomber_core/telemetry/telemetry.py:750\u001b[0m, in \u001b[0;36mTelemetry.log_call.<locals>._log_call.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m     injected_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[1;32m    749\u001b[0m     injected_args\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m1\u001b[39m, _payload)\n\u001b[0;32m--> 750\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minjected_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    752\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(_payload, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/ploomber_core/exceptions.py:109\u001b[0m, in \u001b[0;36mmodify_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    111\u001b[0m         _add_community_link(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/sql/magic.py:473\u001b[0m, in \u001b[0;36mSqlMagic._execute\u001b[0;34m(self, payload, line, cell, local_ns, is_interactive_mode)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 473\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    476\u001b[0m         result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;66;03m# Instead of returning values, set variables directly in the\u001b[39;00m\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;66;03m# users namespace. Variable names given by column names\u001b[39;00m\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautopandas \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautopolars:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/sql/run.py:546\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(conn, sql, config)\u001b[0m\n\u001b[1;32m    543\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;28mstr\u001b[39m(statement))\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 546\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m(statement)\n\u001b[1;32m    547\u001b[0m     _commit(conn\u001b[38;5;241m=\u001b[39mconn, config\u001b[38;5;241m=\u001b[39mconfig, manual_commit\u001b[38;5;241m=\u001b[39mmanual_commit)\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mfeedback:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'execute'"
     ]
    }
   ],
   "source": [
    "result = agent.run(\"How many records are there\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "230a7ec6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent custom-at-query-time started with {'query': 'How many unique levels of education are there', 'params': None}\n",
      "\u001b[32mcheck\u001b[0m\u001b[32m the\u001b[0m\u001b[32m unique\u001b[0m\u001b[32m values\u001b[0m\u001b[32m in\u001b[0m\u001b[32m the\u001b[0m\u001b[32m '\u001b[0m\u001b[32meducation\u001b[0m\u001b[32m'\u001b[0m\u001b[32m column\u001b[0m\u001b[32m of\u001b[0m\u001b[32m the\u001b[0m\u001b[32m '\u001b[0m\u001b[32mbank\u001b[0m\u001b[32m'\u001b[0m\u001b[32m table\u001b[0m\u001b[32m.\u001b[0m\u001b[32m I\u001b[0m\u001b[32m can\u001b[0m\u001b[32m do\u001b[0m\u001b[32m this\u001b[0m\u001b[32m using\u001b[0m\u001b[32m an\u001b[0m\u001b[32m SQL\u001b[0m\u001b[32m query\u001b[0m\u001b[32m with\u001b[0m\u001b[32m the\u001b[0m\u001b[32m DISTINCT\u001b[0m\u001b[32m keyword\u001b[0m\u001b[32m.\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m:\u001b[0m\u001b[32m J\u001b[0m\u001b[32mupy\u001b[0m\u001b[32mSQL\u001b[0m\u001b[32m_Query\u001b[0m\u001b[32m\n",
      "\u001b[0m\u001b[32mTool\u001b[0m\u001b[32m Input\u001b[0m\u001b[32m:\u001b[0m\u001b[32m select\u001b[0m\u001b[32m distinct\u001b[0m\u001b[32m education\u001b[0m\u001b[32m from\u001b[0m\u001b[32m bank\u001b[0m\u001b[32m\n",
      "\u001b[0m"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb:///bank.duck.db&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb:///bank.duck.db'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'execute'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHow many unique levels of education are there\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/haystack/agents/base.py:359\u001b[0m, in \u001b[0;36mAgent.run\u001b[0;34m(self, query, max_steps, params)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m agent_step\u001b[38;5;241m.\u001b[39mis_last():\n\u001b[0;32m--> 359\u001b[0m         agent_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_agent_finish(agent_step)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/haystack/agents/base.py:373\u001b[0m, in \u001b[0;36mAgent._step\u001b[0;34m(self, query, current_step, params)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_agent_step(next_step)\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# run the tool selected by the LLM\u001b[39;00m\n\u001b[0;32m--> 373\u001b[0m observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_node_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m next_step\u001b[38;5;241m.\u001b[39mis_last() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;66;03m# save the input, output and observation to memory (if memory is enabled)\u001b[39;00m\n\u001b[1;32m    376\u001b[0m memory_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_data_for_memory(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mquery, output\u001b[38;5;241m=\u001b[39mprompt_node_response, observation\u001b[38;5;241m=\u001b[39mobservation)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/haystack/agents/base.py:178\u001b[0m, in \u001b[0;36mToolsManager.run_tool\u001b[0;34m(self, llm_response, params)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    177\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_tool_error(e, tool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtools[tool_name])\n\u001b[0;32m--> 178\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tool_result\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/haystack/agents/base.py:167\u001b[0m, in \u001b[0;36mToolsManager.run_tool\u001b[0;34m(self, llm_response, params)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_tool_start(tool_input, tool\u001b[38;5;241m=\u001b[39mtool)\n\u001b[0;32m--> 167\u001b[0m     tool_result \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mon_tool_finish(\n\u001b[1;32m    169\u001b[0m         tool_result,\n\u001b[1;32m    170\u001b[0m         observation_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObservation: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    174\u001b[0m         tool_input\u001b[38;5;241m=\u001b[39mtool_input,\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/haystack/agents/base.py:92\u001b[0m, in \u001b[0;36mTool.run\u001b[0;34m(self, tool_input, params)\u001b[0m\n\u001b[1;32m     90\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_or_node(tool_input)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 92\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipeline_or_node\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_result(result)\n",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m, in \u001b[0;36mJupySQLQuery.run\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msql\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m{{\u001b[39;49m\u001b[38;5;124;43mquery}}\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     output \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query,\n\u001b[1;32m     15\u001b[0m         \n\u001b[1;32m     16\u001b[0m     }\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2417\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2417\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2420\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2421\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/sql/magic.py:318\u001b[0m, in \u001b[0;36mSqlMagic.execute\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;129m@no_var_expand\u001b[39m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;129m@needs_local_scope\u001b[39m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;129m@line_magic\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msql\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    290\u001b[0m )\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, line\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, cell\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, local_ns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    Runs SQL statement against a database, specified by\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m    SQLAlchemy connect string.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m \n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcell\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_ns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_interactive_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/ploomber_core/telemetry/telemetry.py:750\u001b[0m, in \u001b[0;36mTelemetry.log_call.<locals>._log_call.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m     injected_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(args)\n\u001b[1;32m    749\u001b[0m     injected_args\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m1\u001b[39m, _payload)\n\u001b[0;32m--> 750\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minjected_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    752\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(_payload, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/ploomber_core/exceptions.py:109\u001b[0m, in \u001b[0;36mmodify_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    111\u001b[0m         _add_community_link(e)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/sql/magic.py:473\u001b[0m, in \u001b[0;36mSqlMagic._execute\u001b[0;34m(self, payload, line, cell, local_ns, is_interactive_mode)\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 473\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    476\u001b[0m         result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;66;03m# Instead of returning values, set variables directly in the\u001b[39;00m\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;66;03m# users namespace. Variable names given by column names\u001b[39;00m\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautopandas \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautopolars:\n",
      "File \u001b[0;32m~/anaconda3/envs/llm-env/lib/python3.10/site-packages/sql/run.py:546\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(conn, sql, config)\u001b[0m\n\u001b[1;32m    543\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;28mstr\u001b[39m(statement))\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 546\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m(statement)\n\u001b[1;32m    547\u001b[0m     _commit(conn\u001b[38;5;241m=\u001b[39mconn, config\u001b[38;5;241m=\u001b[39mconfig, manual_commit\u001b[38;5;241m=\u001b[39mmanual_commit)\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39mfeedback:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'execute'"
     ]
    }
   ],
   "source": [
    "result = agent.run(\"How many unique levels of education are there\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c6d1ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "result = agent.run(\"How many unique levels of education are there, \\\n",
    "                    what is the average employee age? \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b210a92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Pros y contras de LangChain</h3>\n",
    "\n",
    "**Pros**\n",
    "\n",
    "1. Fácil de empezar a usar\n",
    "2. Se mapea fácilmente al punto final de completado de chat de la API de OpenAI\n",
    "3. Puede conectarse fácilmente a una variedad de aplicaciones basadas en tu definición de función\n",
    "\n",
    "\n",
    "**Contras**\n",
    "\n",
    "1. Preocupaciones de seguridad\n",
    "2. Evaluación de resultados\n",
    "3. Despliegue\n",
    "4. La integración con LLMs abiertos y alojados parece estar en etapas iniciales\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5ba266",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 align='center'>Pros y contras de Haystack</h3>\n",
    "\n",
    "**Pros**\n",
    "\n",
    "1. Marco establecido con un enfoque en aplicaciones de NLP listas para producción\n",
    "2. Constantemente se adapta a nuevos cambios y construye sobre su marco de trabajo\n",
    "3. Amigable para el lanzamiento a producción\n",
    "4. Ofrece soluciones para tus documentos personalizados y acceso a una variedad de sabores de base de datos\n",
    "5. Ofrece plantillas de indicaciones\n",
    "6. NLP pipelines listas para ser usadas\n",
    "\n",
    "**Contras**\n",
    "\n",
    "1. Curva de aprendizaje más pronunciada\n",
    "2. La opción de lanzamiento a producción actual es la API REST, pero otras opciones actualmente no están disponibles\n",
    "3. Limitaciones en los tipos de archivos que puede manejar (actualmente no se admiten PDF y markdown)\n",
    "4. Enfoque más estrecho cuando se trata de los tipos de agentes que admite (aunque puedes crear agentes personalizados, a través de nodos personalizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d290e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'>Reflexiones finales</h1>\n",
    "\n",
    "* La ingeniería de indicaciones (prompt engineering) comienza con un proyecto bien definido y una elección clara de la arquitectura del transformador\n",
    "* Las indicaciones son generalmente el primer paso al usar un LLM\n",
    "* Las indicaciones a través de la API de OpenAI proporcionan una solución rápida para prototipos, pero tiene limitaciones cuando se trata de datos/documentos privados\n",
    "* Las indicaciones a los LLMs de código abierto requieren la comprensión de la arquitectura del transformador y la apertura para afinar\n",
    "* Exploramos dos marcos de trabajo de código abierto que te permiten aumentar la funcionalidad de los LLMs a través de agentes\n",
    "* LangChain aborda a los agentes a través de componentes y cadenas\n",
    "* Haystack aborda a los agentes en términos de expansión de la funcionalidad de nodos de indicaciones, pipelines y una tienda de documentos."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python-LLM",
   "language": "python",
   "name": "llm-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
